{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and Track Objects in Lyft Dataset and create Carmaker Files\n",
    "This Notebook is for creating the required files and running the detector training and generating the simulation files\n",
    "### It is necessary to run this Notebook in the lyft_env environment\n",
    "First install the conda environment lyft_env using the lyft-environment.yaml file.\n",
    "Activate the environment in Jupyter using: Kernel->Change Kernel->conda_env:lyft_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from second.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyft-Detector Training\n",
    "The Detector is trained using the train dataset. Model changes can be made in the config file.\n",
    "You need to change all paths according to your locations and the dataset structure described on the project page needs to be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LYFT_TRAINVAL_DATASET_ROOT = '/home/itiv/Desktop/lyft-dataset/'\n",
    "config_path = 'Lyft-Detector/second.pytorch/second/configs/nuscenes/all.pp.lowa_large_range_v3.config'\n",
    "model_path = 'Lyft-Detector/second.pytorch/second/model/model_large_range_v3_2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_CUDA_DRIVER=/usr/lib/x86_64-linux-gnu/libcuda.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 7.9 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.2 seconds.\n",
      "======\n",
      "total scene num: 180\n",
      "exist scene num: 180\n",
      "train scene: 147, val scene: 33\n",
      "[100.0%][===================>][64.13it/s][06:00>00:00]    \n",
      "train sample: 18522, val sample: 4158\n"
     ]
    }
   ],
   "source": [
    "## create database .pkl files\n",
    "!python Lyft-Detector/second.pytorch/second/create_data.py nuscenes_data_prep --root_path=$LYFT_TRAINVAL_DATASET_ROOT  --version=\"v1.0-trainval\" --dataset_name=\"NuScenesDataset\" --max_sweeps=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15358/15358 [00:03<00:00, 4742.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-Truth objects saved to: /home/itiv/Desktop/lyft-dataset//gt_data_val.json\n"
     ]
    }
   ],
   "source": [
    "## create Ground-Truth .json files \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from scipy.spatial.transform import Rotation as R \n",
    "from math import cos, sin, pi\n",
    "from lyft_dataset_sdk.lyftdataset import *\n",
    "from lyft_dataset_sdk.utils.data_classes import LidarPointCloud, Box, Quaternion\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "from lyft_dataset_sdk.eval.detection.mAP_evaluation import Box3D, recall_precision\n",
    "\n",
    "\n",
    "LYFT_DATASET_ROOT = LYFT_TRAINVAL_DATASET_ROOT\n",
    "\n",
    "\n",
    "phase = 'train'\n",
    "version = 'v1.0-trainval' if phase=='train' else 'v1.0-test'\n",
    "nusc = NuScenes(dataroot=f'{LYFT_DATASET_ROOT}/', version=version, verbose=0) \n",
    "lyft=nusc\n",
    "\n",
    "\n",
    "#info_path = f'{LYFT_DATASET_ROOT}/infos_val.pkl'\n",
    "info_path = f'{LYFT_DATASET_ROOT}/infos_train.pkl'\n",
    "# info_path = '../../../data/nuscenes/v1.0-trainval/infos_train.pkl'\n",
    "#info_path = '../../../data/nuscenes/v1.0-trainval/infos_val.pkl'\n",
    "with open(info_path, 'rb') as f:\n",
    "    info = pickle.load(f)['infos']\n",
    "    \n",
    "# only for nuscenes\n",
    "NameMapping = {\n",
    "    'movable_object.barrier': 'barrier',\n",
    "    'vehicle.bicycle': 'bicycle',\n",
    "    'vehicle.bus.bendy': 'bus',\n",
    "    'vehicle.bus.rigid': 'bus',\n",
    "    'vehicle.car': 'car',\n",
    "    'vehicle.construction': 'construction_vehicle',\n",
    "    'vehicle.motorcycle': 'motorcycle',\n",
    "    'human.pedestrian.adult': 'pedestrian',\n",
    "    'human.pedestrian.child': 'pedestrian',\n",
    "    'human.pedestrian.construction_worker': 'pedestrian',\n",
    "    'human.pedestrian.police_officer': 'pedestrian',\n",
    "    'movable_object.trafficcone': 'traffic_cone',\n",
    "    'vehicle.trailer': 'trailer',\n",
    "    'vehicle.truck': 'truck'\n",
    "}\n",
    "\n",
    "gt_data = [] \n",
    "for inf in tqdm(info):\n",
    "    sample_token = inf['token']\n",
    "    sample = lyft.get('sample', sample_token)\n",
    "    for ann_token in sample['anns']:\n",
    "        ann_record = lyft.get('sample_annotation', ann_token)\n",
    "        try:\n",
    "            data = {\n",
    "                'sample_token': sample_token,\n",
    "                'translation': ann_record['translation'],\n",
    "                'size': ann_record['size'],\n",
    "                'rotation': ann_record['rotation'],\n",
    "                'name': ann_record['category_name']\n",
    "                #'name': NameMapping[ann_record['category_name']]\n",
    "            }\n",
    "           # print(ann_record['category_name'])\n",
    "            gt_data.append(data)\n",
    "        except Exception as e:\n",
    "            pass # for nuscenes, not using some categories\n",
    "\n",
    "        \n",
    "gt_data_path = f'{LYFT_DATASET_ROOT}/gt_data_val.json'\n",
    "with open(gt_data_path, 'w') as f:\n",
    "    json.dump(gt_data, f, indent=2)\n",
    "    \n",
    "    \n",
    "print(f'Ground-Truth objects saved to: {gt_data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set in config file\n"
     ]
    }
   ],
   "source": [
    "## set paths in config file...\n",
    "\n",
    "config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with open(config_path, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, config)\n",
    "config.train_input_reader.dataset.kitti_info_path = LYFT_TRAINVAL_DATASET_ROOT+\"/infos_train.pkl\"\n",
    "config.train_input_reader.dataset.kitti_root_path = LYFT_TRAINVAL_DATASET_ROOT\n",
    "\n",
    "config.train_input_reader.preprocess.database_sampler.database_info_path = LYFT_TRAINVAL_DATASET_ROOT+\"/infos_train.pkl\"\n",
    "    \n",
    "config.eval_input_reader.dataset.kitti_info_path = LYFT_TRAINVAL_DATASET_ROOT+\"/infos_val.pkl\"\n",
    "config.eval_input_reader.dataset.kitti_root_path = LYFT_TRAINVAL_DATASET_ROOT\n",
    "\n",
    "config_text = text_format.MessageToString(config)\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(config_text)\n",
    "\n",
    "print('Paths set in config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ./Lyft-Detector/second.pytorch/second/pytorch/train.py train --config_path=Lyft-Detector/second.pytorch/second/configs/nuscenes/all.pp.lowa_large_range_v3.config --model_dir=Lyft-Detector/second.pytorch/second/model/model_large_range_v3_2\n"
     ]
    }
   ],
   "source": [
    "##start training\n",
    "\n",
    "#!python ./Lyft-Detector/second.pytorch/second/pytorch/train.py train --config_path=$config_path --model_dir=$model_path\n",
    "\n",
    "print('python ./Lyft-Detector/second.pytorch/second/pytorch/train.py train --config_path='+config_path+' --model_dir='+model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tracks for Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set vars\n",
    "LYFT_DATASET_ROOT = '/home/itiv/Desktop/lyft-kaggle-dataset/train/'\n",
    "CONFIG_FILE = \"./Lyft-Detector/second.pytorch/second/configs/nuscenes/all.pp.lowa.config\"\n",
    "MODEL_FILE = './Lyft-Detector/second.pytorch/second/model/model_standard/voxelnet-48698.tckpt'\n",
    "MODEL = 'standard'\n",
    "VERSION = \"v1.0-trainval\" #v1.0-test for test-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 7.8 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.2 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "##Choose a scene..first load dataset\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "\n",
    "data_path = LYFT_DATASET_ROOT\n",
    "json_path = data_path+VERSION\n",
    "# Load the dataset\n",
    "# Adjust the dataroot parameter below to point to your local dataset path.\n",
    "# The correct dataset path contains at least the following four folders (or similar): images, lidar, maps, v1.0.1-train\n",
    "level5data = LyftDataset(data_path=data_path, json_path=json_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': '', 'first_sample_token': '779fb76f1b70ff92cf586bf2ed5f8ac0e9cf5c28fde2c33760cd3219840e529d', 'name': 'host-a011-lidar0-1236119823299280856-1236119848199397346', 'log_token': 'af749b4da1ab470bd4af7bab1a1e9ea358349839844de30291ec3c1c15f94f48', 'last_sample_token': 'a3ad6fd0f3063171545e575a93f0c2e2cabd1bf9bf16e00edbcbbc27540f62c9', 'nbr_samples': 126, 'token': 'af749b4da1ab470bd4af7bab1a1e9ea358349839844de30291ec3c1c15f94f48'}\n"
     ]
    }
   ],
   "source": [
    "##Choose a scene..\n",
    "#level5data.list_scenes()\n",
    "\n",
    "SCENE_NUM = 10#119#106#10\n",
    "\n",
    "scene = level5data.scene[SCENE_NUM]\n",
    "scene_token = scene['token']\n",
    "\n",
    "print(scene)\n",
    "\n",
    "\n",
    "#last_sample = level5data.get('sample', scene['last_sample_token'])\n",
    "\n",
    "#sample_token = scene['first_sample_token']\n",
    "#timestamp = 0\n",
    "#while sample_token is not '':\n",
    "#    sample = level5data.get('sample', sample_token)\n",
    "#    print((sample['timestamp']-timestamp)/1000000)\n",
    "#    timestamp = sample['timestamp']\n",
    "#    sample_token = sample['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "level5data.render_scene(scene_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_CUDA_DRIVER=/usr/lib/x86_64-linux-gnu/libcuda.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 6.6 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.2 seconds.\n",
      "======\n",
      "total scene num: 180\n",
      "exist scene num: 180\n",
      "test scene: 1\n",
      "[100.0%][===================>][61.92it/s][06:14>00:00]    \n",
      "custom scene sample: 126\n",
      "saved to: infos_af749b4da1ab470bd4af7bab1a1e9ea358349839844de30291ec3c1c15f94f48.pkl\n"
     ]
    }
   ],
   "source": [
    "## create database .pkl files\n",
    "\n",
    "#TODO - create dummy ann files\n",
    "#LYFT_TRAINVAL_DATASET_ROOT = '/home/itiv/Desktop/lyft-kaggle-dataset/test'\n",
    "#!python Lyft-Detector/second.pytorch/second/create_data.py nuscenes_data_prep --root_path=$LYFT_TRAINVAL_DATASET_ROOT  --version=\"v1.0-test\" --dataset_name=\"NuScenesDataset\" --scene_token=$scene_token --max_sweeps=10\n",
    "version = VERSION\n",
    "!python Lyft-Detector/second.pytorch/second/create_data.py nuscenes_data_prep --root_path=$LYFT_DATASET_ROOT  --version=$version --dataset_name=\"NuScenesDataset\" --scene_token=$scene_token --max_sweeps=10\n",
    "##todo make this faster!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set in config file\n"
     ]
    }
   ],
   "source": [
    "## set paths in config file...not necessary for detection generation but throws error if files are invalid...\n",
    "\n",
    "config_path = CONFIG_FILE\n",
    "#LYFT_TRAINVAL_DATASET_ROOT = '/home/itiv/Desktop/lyft-kaggle-dataset/train'\n",
    "info_path = LYFT_DATASET_ROOT+'/infos_'+scene_token+'.pkl'\n",
    "\n",
    "config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with open(config_path, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, config)\n",
    "config.train_input_reader.dataset.kitti_info_path = info_path\n",
    "config.train_input_reader.dataset.kitti_root_path = LYFT_DATASET_ROOT\n",
    "\n",
    "config.train_input_reader.preprocess.database_sampler.database_info_path = info_path\n",
    "    \n",
    "config.eval_input_reader.dataset.kitti_info_path = info_path\n",
    "config.eval_input_reader.dataset.kitti_root_path = LYFT_DATASET_ROOT\n",
    "\n",
    "config_text = text_format.MessageToString(config)\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(config_text)\n",
    "\n",
    "print('Paths set in config file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting...this might take several minutes...\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_CUDA_DRIVER=/usr/lib/x86_64-linux-gnu/libcuda.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "############### Finished ###############\n"
     ]
    }
   ],
   "source": [
    "##Perform detection\n",
    "\n",
    "\n",
    "config_path = CONFIG_FILE\n",
    "ckpt_path = MODEL_FILE\n",
    "#info_path = LYFT_DATASET_ROOT+'/infos_'+scene_token+'.pkl'\n",
    "root_path = LYFT_DATASET_ROOT\n",
    "result_path = LYFT_DATASET_ROOT\n",
    "print('Detecting...this might take several minutes...')\n",
    "!python ./Lyft-Detector/second.pytorch/second/detect.py detect --scene_token=$scene_token --config_path=$config_path --ckpt_path=$ckpt_path --info_path=$info_path --root_path=$root_path --result_path=$result_path\n",
    "\n",
    "\n",
    "print('############### Finished ###############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track nuscenes\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 6.6 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.4 seconds.\n",
      "======\n",
      "Loaded results from /home/itiv/Desktop/lyft-kaggle-dataset/train//detections_af749b4da1ab470bd4af7bab1a1e9ea358349839844de30291ec3c1c15f94f48.json. Found detections for 126 samples.\n",
      "  0%|                                                   | 0/126 [00:00<?, ?it/s]./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py:116: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function roty failed at nopython mode lowering due to: \n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 123:\n",
      "def roty(t):\n",
      "    <source elided>\n",
      "                     [0,  1,  0],\n",
      "                     [-s, 0,  c]])\n",
      "                     ^\n",
      "\n",
      "[1] During: lowering \"$0.24 = build_list(items=[Var($0.14, main.py:121), Var($0.18, main.py:122), Var($0.23, main.py:123)])\" at ./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py (123)\n",
      "  @jit\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"roty\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 117:\n",
      "@jit       \n",
      "def roty(t):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 117:\n",
      "@jit       \n",
      "def roty(t):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "100%|████████████████████████████████████████| 126/126 [00:01<00:00, 105.77it/s]\n",
      "Total Tracking took: 1.141 for 126 frames or 110.5 FPS\n"
     ]
    }
   ],
   "source": [
    "#Perform Tracking\n",
    "\n",
    "root_path = LYFT_DATASET_ROOT\n",
    "result_path = LYFT_DATASET_ROOT\n",
    "version = VERSION\n",
    "detection_file = result_path+'/detections_'+scene_token+'.json'\n",
    "!python ./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py track --save_root=$root_path --version=$version --detection_file=$detection_file --data_root=$root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 98 tracks\n",
      "       Car 1    Car 2    Car 3    Car 4    Car 6     Car 8 Car 12 Car 20  \\\n",
      "0    2.58975  2.59041  2.59443   2.5107  2.56918 -0.695868    NaN    NaN   \n",
      "1    2.59373  2.60045  2.58969  2.55823  2.56754 -0.680916    NaN    NaN   \n",
      "2    2.59683  2.61105  2.58531  2.57271  2.54857    2.5018    NaN    NaN   \n",
      "3    2.59938  2.60358  2.58372  2.57973  2.54812    2.5018    NaN    NaN   \n",
      "4    2.60186  2.60116  2.58611  2.58732  2.56126   2.55547    NaN    NaN   \n",
      "..       ...      ...      ...      ...      ...       ...    ...    ...   \n",
      "121      NaN      NaN      NaN   2.6209      NaN       NaN    NaN    NaN   \n",
      "122      NaN      NaN      NaN  2.62239      NaN       NaN    NaN    NaN   \n",
      "123      NaN      NaN      NaN  2.62221      NaN       NaN    NaN    NaN   \n",
      "124      NaN      NaN      NaN  2.62351      NaN       NaN    NaN    NaN   \n",
      "125      NaN      NaN      NaN  2.62171      NaN       NaN    NaN    NaN   \n",
      "\n",
      "    Car 35 Car 37  ... Car 169 Car 173 Car 174 Car 184 Car 185 Car 188  \\\n",
      "0      NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "1      NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "2      NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "3      NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "4      NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
      "..     ...    ...  ...     ...     ...     ...     ...     ...     ...   \n",
      "121    NaN    NaN  ...    -0.5     2.6     NaN     2.6     2.6     NaN   \n",
      "122    NaN    NaN  ...    -0.5     2.6     NaN     2.6     2.6     NaN   \n",
      "123    NaN    NaN  ...    -0.5     2.6     NaN     2.6     2.6     NaN   \n",
      "124    NaN    NaN  ...    -0.5     2.6     NaN     2.6     2.6     NaN   \n",
      "125    NaN    NaN  ...    -0.5     2.6     NaN     2.6     2.6     NaN   \n",
      "\n",
      "    Car 192 Car 198 Car 199 Car 202  \n",
      "0       NaN     NaN     NaN     NaN  \n",
      "1       NaN     NaN     NaN     NaN  \n",
      "2       NaN     NaN     NaN     NaN  \n",
      "3       NaN     NaN     NaN     NaN  \n",
      "4       NaN     NaN     NaN     NaN  \n",
      "..      ...     ...     ...     ...  \n",
      "121    -2.4    -0.5     2.6     2.6  \n",
      "122    -2.4    -0.5     2.6     2.6  \n",
      "123    -2.4    -0.5     2.6     2.6  \n",
      "124     NaN    -0.5     2.6     2.6  \n",
      "125     NaN    -0.5     2.6     2.6  \n",
      "\n",
      "[126 rows x 51 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' dphi = math.pi/10\\nfor (columnName, columnData) in traffic_orientation.iteritems():\\n    prev_orientation = None\\n    \\n    for index,item in enumerate(columnData.tolist()):\\n        if prev_orientation is None:\\n            prev_orientation = traffic_orientation.at[index, columnName]\\n            continue\\n        if not math.isnan(item):\\n            if abs(traffic_orientation.at[index, columnName]-prev_orientation) > math.pi:\\n                if(traffic_orientation.at[index, columnName]-prev_orientation > 0):\\n                    traffic_orientation.at[index, columnName] = prev_orientation-dphi\\n                else:\\n                    traffic_orientation.at[index, columnName] = prev_orientation+dphi\\n            elif abs(prev_orientation-traffic_orientation.at[index, columnName]) > dphi:\\n                if(traffic_orientation.at[index, columnName]-prev_orientation > 0):\\n                    traffic_orientation.at[index, columnName] = prev_orientation+dphi\\n                else:\\n                    traffic_orientation.at[index, columnName] = prev_orientation-dphi\\n            prev_orientation = traffic_orientation.at[index, columnName]\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create carmaker files...\n",
    "\n",
    "### load track result dict\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyquaternion import Quaternion\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "from operator import add\n",
    "from scipy.stats import beta\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "tracking_file = LYFT_DATASET_ROOT+'/tracking_results_'+scene_token+'.json'\n",
    "\n",
    "with open(tracking_file) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "tracking_ids = []\n",
    "sample_token = scene['first_sample_token']\n",
    "timestamp = 0\n",
    "for index in range(scene['nbr_samples']):\n",
    "    sample = level5data.get('sample', sample_token)\n",
    "    for detection_dict in data['results'][sample_token]:\n",
    "        if not int(detection_dict['tracking_id']) in tracking_ids:\n",
    "            tracking_ids.append(int(detection_dict['tracking_id']))\n",
    "        else:\n",
    "            counter += 1\n",
    "    sample_token = sample['next']\n",
    "    if sample_token is '':\n",
    "        break\n",
    "\n",
    "tracking_ids.sort()            \n",
    "#print(tracking_ids)\n",
    "\n",
    "print(f'Extracted {len(tracking_ids)} tracks')\n",
    "\n",
    "\n",
    "index = range(scene['nbr_samples'])\n",
    "columns = [\"Car \"+str(x) for x in tracking_ids]\n",
    "\n",
    "\n",
    "traffic_coords = pd.DataFrame(index=index, columns=columns)\n",
    "traffic_coords = traffic_coords.astype(object)\n",
    "\n",
    "traffic_orientation = pd.DataFrame(index=index, columns=columns)\n",
    "traffic_orientation = traffic_orientation.astype(object)\n",
    "\n",
    "traffic_sizes = pd.DataFrame(index=index, columns=columns)\n",
    "traffic_sizes = traffic_sizes.astype(object)\n",
    "\n",
    "columns = ['Timestamp','Translation','Yaw']\n",
    "ego_info = pd.DataFrame(index=index, columns=columns)\n",
    "ego_info = ego_info.astype(object)\n",
    "\n",
    "\n",
    "translation_offset = None\n",
    "\n",
    "sample_token = scene['first_sample_token']\n",
    "for index in range(scene['nbr_samples']):\n",
    "    sample = level5data.get('sample', sample_token)\n",
    "    sample_data = level5data.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "    \n",
    "    ego_pose = level5data.get('ego_pose', sample_data['ego_pose_token'])\n",
    "    \n",
    "    if translation_offset is None:\n",
    "        translation_offset = ego_pose['translation']\n",
    "    \n",
    "    ego_info.at[index, 'Timestamp'] = ego_pose['timestamp']\n",
    "    ego_info.at[index, 'Yaw'] = Quaternion(ego_pose['rotation']).yaw_pitch_roll[0]\n",
    "    ego_info.at[index, 'Translation'] = list(map(operator.sub,ego_pose['translation'],translation_offset))\n",
    "    #filter pedestrians and bicycles    \n",
    "    for detection_dict in data['results'][sample_token]:\n",
    "        if not (detection_dict['tracking_name'] == 'bicycle' or detection_dict['tracking_name'] == 'pedestrian'):\n",
    "            traffic_coords.at[index, 'Car '+detection_dict['tracking_id']] =  list(map(operator.sub,detection_dict['translation'],translation_offset))\n",
    "            traffic_orientation.at[index, 'Car '+detection_dict['tracking_id']] = Quaternion(detection_dict['rotation']).yaw_pitch_roll[0]\n",
    "            traffic_sizes.at[index, 'Car '+detection_dict['tracking_id']] = detection_dict['size']\n",
    "    sample_token = sample['next']\n",
    "    if sample_token is '':\n",
    "        break\n",
    "\n",
    "#filter short occurence traffic <1s\n",
    "for index,entrys in traffic_coords.count().iteritems():\n",
    "    if entrys < 5:\n",
    "        traffic_coords.drop(index,axis=1,inplace=True)\n",
    "        traffic_sizes.drop(index,axis=1,inplace=True)\n",
    "        traffic_orientation.drop(index,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "def dist(l1,l2):\n",
    "    d = math.sqrt((l1[0]-l2[0])**2+(l1[1]-l2[1])**2+(l1[2]-l2[2])**2)\n",
    "    return d\n",
    " \n",
    "#filter intersection traffic with ego\n",
    "for (columnName, columnData) in traffic_coords.iteritems():\n",
    "    for index,item in enumerate(traffic_coords[columnName]):\n",
    "        if type(ego_info.at[index, 'Translation']) is list and type(item) is list and dist(item,ego_info.at[index, 'Translation']) < 1:\n",
    "            traffic_coords.drop(columnName,axis=1,inplace=True)\n",
    "            traffic_sizes.drop(columnName,axis=1,inplace=True)\n",
    "            traffic_orientation.drop(columnName,axis=1,inplace=True)\n",
    "            print(f'dropped {columnName}')\n",
    "        \n",
    "        \n",
    "#interpolate short NaNs\n",
    "for (columnName, columnData) in traffic_coords.iteritems():\n",
    "    for index,item in enumerate(traffic_coords[columnName]):\n",
    "        if type(item) is list and len(traffic_coords[columnName])>index+1 and type(traffic_coords[columnName][index+1]) is not list:\n",
    "            for step in range(10):\n",
    "                if len(traffic_coords[columnName])>index+1+step and type(traffic_coords[columnName][index+1+step]) is list:\n",
    "                    v = list(map(operator.sub, traffic_coords[columnName][index+1+step],item))\n",
    "                    traffic_coords[columnName][index+1] = list(map(operator.add, item, [x / (step+1) for x in v]))\n",
    "                    traffic_orientation[columnName][index+1] = (traffic_orientation[columnName][index+1+step]-traffic_orientation[columnName][index])/(step+1)\n",
    "                    #print(f'{item} {traffic_coords[columnName][index+1]} {traffic_coords[columnName][index+1+step]}')\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def plotVal(x):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import stats\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.distplot(x);\n",
    "    \n",
    "    \n",
    "#suppress random orientation changes \n",
    "#driving vehicle: orientation according to direction\n",
    "#standing vehicle: orientation according to most detected\n",
    "\n",
    "dt = 0.2 #Periodendauer\n",
    "for (columnName, columnData) in traffic_orientation.iteritems():\n",
    "\n",
    "    traffic_speed = []\n",
    "    moving = False\n",
    "    for index,item in enumerate(traffic_coords[columnName]):\n",
    "        if type(item) is list and len(traffic_coords[columnName])>index+1 and type(traffic_coords[columnName][index+1]) is list:\n",
    "            traffic_speed.append(abs(dist(item,traffic_coords[columnName][index+1])/dt))\n",
    "        else:\n",
    "            traffic_speed.append(np.nan)\n",
    "    \n",
    "    prev_orientation = None\n",
    "    not_moving_orientations = []\n",
    "    not_moving_start_index = 0\n",
    "    for index,item in enumerate(traffic_speed):\n",
    "\n",
    "        if moving and (abs(item) < 1.5 or math.isnan(item)):\n",
    "            moving = False\n",
    "            not_moving_orientations = []\n",
    "            not_moving_start_index = index\n",
    "        elif not moving and (abs(item) > 2 or math.isnan(item)): \n",
    "            if len(not_moving_orientations) > 1:\n",
    "                orientation,_ = (Counter(not_moving_orientations).most_common(1)[0])\n",
    "                if not math.isnan(orientation):\n",
    "                    for idx in range(index-not_moving_start_index):\n",
    "                        traffic_orientation[columnName][index-idx] = orientation\n",
    "                \n",
    "                #plotVal(not_moving_orientations)\n",
    "            moving = True\n",
    "        if not math.isnan(item):\n",
    "            if index == len(traffic_speed)-1:\n",
    "                if prev_orientation is not None:\n",
    "                    traffic_orientation[columnName][index] = prev_orientation\n",
    "            elif moving and type(traffic_coords[columnName][index]) is list and type(traffic_coords[columnName][index+1]) is list:\n",
    "                v = list(map(operator.sub, traffic_coords[columnName][index+1],traffic_coords[columnName][index]))\n",
    "                yaw = math.atan2(v[0],v[1])\n",
    "                #traffic_orientation[columnName][index] = yaw -> bad results...\n",
    "            elif moving and type(traffic_coords[columnName][index]) is list and type(traffic_coords[columnName][index+1]) is not list and prev_orientation is not None:\n",
    "                traffic_orientation[columnName][index] = prev_orientation\n",
    "            elif not moving:\n",
    "                not_moving_orientations.append(round(traffic_orientation[columnName][index],1))\n",
    "                \n",
    "            prev_orientation = traffic_orientation[columnName][index]\n",
    "\n",
    "\n",
    "\n",
    "print(traffic_orientation)           \n",
    "            \n",
    "\n",
    "#max radian change:\n",
    "''' dphi = math.pi/10\n",
    "for (columnName, columnData) in traffic_orientation.iteritems():\n",
    "    prev_orientation = None\n",
    "    \n",
    "    for index,item in enumerate(columnData.tolist()):\n",
    "        if prev_orientation is None:\n",
    "            prev_orientation = traffic_orientation.at[index, columnName]\n",
    "            continue\n",
    "        if not math.isnan(item):\n",
    "            if abs(traffic_orientation.at[index, columnName]-prev_orientation) > math.pi:\n",
    "                if(traffic_orientation.at[index, columnName]-prev_orientation > 0):\n",
    "                    traffic_orientation.at[index, columnName] = prev_orientation-dphi\n",
    "                else:\n",
    "                    traffic_orientation.at[index, columnName] = prev_orientation+dphi\n",
    "            elif abs(prev_orientation-traffic_orientation.at[index, columnName]) > dphi:\n",
    "                if(traffic_orientation.at[index, columnName]-prev_orientation > 0):\n",
    "                    traffic_orientation.at[index, columnName] = prev_orientation+dphi\n",
    "                else:\n",
    "                    traffic_orientation.at[index, columnName] = prev_orientation-dphi\n",
    "            prev_orientation = traffic_orientation.at[index, columnName]\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files to: /home/itiv/Desktop/lyft-kaggle-dataset/train//CarMaker/TestRun//testrun_scene-10-standard\n"
     ]
    }
   ],
   "source": [
    "##create CarMaker Files...\n",
    "import os\n",
    "import random\n",
    "        \n",
    "def dist(l1,l2):\n",
    "    d = math.sqrt((l1[0]-l2[0])**2+(l1[1]-l2[1])**2+(l1[2]-l2[2])**2)\n",
    "    return d\n",
    "\n",
    "CM_PROJECT_DIR =  LYFT_DATASET_ROOT+'/CarMaker'#'C://CM_Projects//maneuver_simu'\n",
    "TESTRUN_DIR = CM_PROJECT_DIR+'/TestRun'#CM_PROJECT_DIR+'//Data//TestRun'\n",
    "SIMINPUT_DIR = CM_PROJECT_DIR+'/SimInput/'#CM_PROJECT_DIR+'//SimInput'\n",
    "\n",
    "if not os.path.exists(CM_PROJECT_DIR):\n",
    "    os.mkdir(CM_PROJECT_DIR)\n",
    "if not os.path.exists(TESTRUN_DIR):\n",
    "    os.mkdir(TESTRUN_DIR)\n",
    "if not os.path.exists(SIMINPUT_DIR):\n",
    "    os.mkdir(SIMINPUT_DIR)\n",
    "\n",
    "TESTRUN_ID = 'scene-'+str(SCENE_NUM)+'-'+MODEL\n",
    "TESTRUN_NAME = f'//testrun_{TESTRUN_ID}'\n",
    "TESTRUN_PATH = TESTRUN_DIR+TESTRUN_NAME\n",
    "TRAFFIC_PROFILE_NAME = f'traffic_profile_{TESTRUN_ID}.txt'\n",
    "TRAFFIC_PROFILE_PATH = SIMINPUT_DIR+TRAFFIC_PROFILE_NAME\n",
    "EGO_PROFILE_NAME = f'ego_profile_{TESTRUN_ID}.txt'\n",
    "EGO_PROFILE_PATH = SIMINPUT_DIR+EGO_PROFILE_NAME\n",
    "\n",
    "content_lines = []\n",
    "content_lines.append('#INFOFILE1.1 - Do not remove this line!\\n\\\n",
    "FileIdent = CarMaker-TestRun 8\\n\\\n",
    "FileCreator = CarMaker 8.1 2019-11-07\\n\\\n",
    "Description:\\n\\\n",
    "Vehicle = UserVehicle_MyCar\\n\\\n",
    "Trailer =\\n\\\n",
    "Tire.0 =\\n\\\n",
    "Tire.1 =\\n\\\n",
    "Tire.2 =\\n\\\n",
    "Tire.3 =\\n\\\n",
    "Snapshot.TimeLimit =\\n\\\n",
    "Snapshot.DistLimit =\\n\\\n",
    "VehicleLoad.0.mass = 0\\n\\\n",
    "VehicleLoad.0.pos = 0 0 0\\n\\\n",
    "VehicleLoad.1.mass = 0\\n\\\n",
    "VehicleLoad.1.pos = 0 0 0\\n\\\n",
    "VehicleLoad.2.mass = 0\\n\\\n",
    "VehicleLoad.2.pos = 0 0 0\\n\\\n",
    "VehicleLoad.3.mass = 0\\n\\\n",
    "VehicleLoad.3.pos = 0 0 0\\n\\\n",
    "TrailerLoad.0.mass = 0\\n\\\n",
    "TrailerLoad.0.pos = 0 0 0\\n\\\n",
    "TrailerLoad.1.mass = 0\\n\\\n",
    "TrailerLoad.1.pos = 0 0 0\\n\\\n",
    "TrailerLoad.2.mass = 0\\n\\\n",
    "TrailerLoad.2.pos = 0 0 0\\n')\n",
    "                     \n",
    "#ego maneuver for every 10th coord\n",
    "\n",
    "time_between_records = 0.2 \n",
    "\n",
    "start_vel = 0#ego_vel[0]\n",
    "man_counter = 1\n",
    "#ego_man = []\n",
    "#for vel in ego_vel[::10]:\n",
    "#    ego_man.append('DrivMan.'+str(man_counter)+'.TimeLimit = '+str(10*time_between_records)+'\\n\\\n",
    "#DrivMan.'+str(man_counter)+'.LongDyn = VelControl '+str(vel*3.6)+' 0.0 1.0 0 1 0\\n\\\n",
    "#DrivMan.'+str(man_counter)+'.LatDyn = Driver 0\\n')\n",
    "#    man_counter += 1\n",
    "    \n",
    "       # +str(start_vel)+\n",
    "content_lines.append('DrivMan.Init.Velocity = 0\\n\\\n",
    "DrivMan.Init.SteerAng = 0\\n\\\n",
    "DrivMan.Init.GearNo = 0\\n\\\n",
    "DrivMan.Init.LaneOffset = 0\\n\\\n",
    "DrivMan.Init.OperatorActive = 1\\n\\\n",
    "DrivMan.Init.OperatorState = drive\\n\\\n",
    "DrivMan.VhclOperator.Kind = IPGOperator 1\\n\\\n",
    "DrivMan.nDMan = '+str(man_counter)+'\\n')\n",
    "\n",
    "content_lines.append('DrivMan.0.TimeLimit = '+str(time_between_records*(len(ego_info)-1))+'\\n\\\n",
    "DrivMan.0.LongDyn = Stop 2.0 0\\n\\\n",
    "DrivMan.0.LatDyn = Driver 0\\n')\n",
    "\n",
    "\n",
    "#write traffic profile file\n",
    "\n",
    "traffic_profile = []\n",
    "traffic_profile.append('# Time')\n",
    "for index,col in enumerate(traffic_coords):\n",
    "    traffic_profile.append(' FM_tx_%d FM_ty_%d FM_tz_%d FM_rz_%d' % (index,index,index,index))\n",
    "traffic_profile.append('\\n')    \n",
    "\n",
    "\n",
    "prev_row = None\n",
    "for time_index, row in traffic_coords.iterrows():\n",
    "    traffic_profile.append('%f'%(time_index*time_between_records))\n",
    "\n",
    "    for car_index,coords in enumerate(row):\n",
    "        if type(coords) is list:\n",
    "            traffic_profile.append(' %f %f %f %f'%(coords[0],coords[1],0.6,traffic_orientation.iloc[time_index,car_index]))\n",
    "        else:\n",
    "            traffic_profile.append(' %f %f %f %f'%(0,0,-100,0))\n",
    "    \n",
    "    prev_row = row\n",
    "    traffic_profile.append('\\n') \n",
    "    \n",
    "\n",
    "    \n",
    "with open(TRAFFIC_PROFILE_PATH, 'w') as f:\n",
    "    for item in traffic_profile:\n",
    "        f.write(\"%s\" % item)\n",
    "\n",
    "\n",
    "traffic_counter = 0   \n",
    "traffic_counter = len(traffic_coords.columns)\n",
    "content_lines.append('Traffic.IFF.FName = SimInput/'+TRAFFIC_PROFILE_NAME+'\\n\\\n",
    "Traffic.IFF.Time.Name = Time\\n\\\n",
    "Traffic.N = %d\\n\\\n",
    "Traffic.SpeedUnit = ms\\n'%traffic_counter)\n",
    "\n",
    "\n",
    "#get average sizes of vehicle\n",
    "\n",
    "traffic_sizes_avr = []\n",
    "for (columnName, columnData) in traffic_sizes.iteritems():\n",
    "    counter = 0\n",
    "    l_sum = 0\n",
    "    for size in columnData.values:\n",
    "        if isinstance(size, list):\n",
    "            counter += 1\n",
    "            l_sum += size[1]\n",
    "    traffic_sizes_avr.append(l_sum/counter)\n",
    "\n",
    "small_car = ['Audi_TT_2015.mobj','Citroen_C3_2015.mobj','Honda_Fit_2015.mobj'] #l<4m\n",
    "medium_car = ['Audi_A4AllRoad_2016.mobj','Audi_A7_2018.mobj','BMW_5_2017.mobj','Honda_CivicTypeR_2018.mobj','MB_AClass_2018.mobj','MB_CClass_2015.mobj','Jaguar_FType_2017.mobj'] #l<5m\n",
    "large_car = ['Chevrolet_Silverado1500_2013.mobj','Chrysler_Pacifica_2016.mobj','Dodge_GrandCaravan_2011.mobj','LandRover_RangeRover_2014.mobj','MB_XClass_2018.mobj'] #l<6m\n",
    "van = ['Ford_Transit_2014.mobj','MB_Sprinter_2013.mobj','MB_Vito_2014.mobj','VW_T6_2016.mobj','VW_Transporter_2016.mobj'] #l<10m\n",
    "bus_truck = ['Coach.mobj','Euro_ConcreteMixer.mobj','Iveco_EurotechLN2_1992.mobj','MAN_TGS_2012.mobj','MB_Actros_1996.mobj','MB_Atego_2013_Move.mobj'] #l>10m\n",
    "    \n",
    "    \n",
    "\n",
    "for index,col in enumerate(traffic_coords): \n",
    "    \n",
    "    vehicle_path = '3D/Vehicles/'\n",
    "    \n",
    "    if traffic_sizes_avr[index]<4:\n",
    "        vehicle_path = vehicle_path+small_car[random.randrange(0,len(small_car),1)]\n",
    "    elif traffic_sizes_avr[index]<5:\n",
    "        vehicle_path = vehicle_path+medium_car[random.randrange(0,len(medium_car),1)]\n",
    "    elif traffic_sizes_avr[index]<6:\n",
    "        vehicle_path = vehicle_path+large_car[random.randrange(0,len(large_car),1)]\n",
    "    elif traffic_sizes_avr[index]<10:\n",
    "        vehicle_path = vehicle_path+van[random.randrange(0,len(van),1)]   \n",
    "    elif traffic_sizes_avr[index]>10:\n",
    "        vehicle_path = vehicle_path+bus_truck[random.randrange(0,len(bus_truck),1)]   \n",
    "\n",
    "    content_lines.append('Traffic.'+str(index)+'.ObjectKind = Movable\\n\\\n",
    "Traffic.'+str(index)+'.ObjectClass = Car\\n\\\n",
    "Traffic.'+str(index)+'.Name = T'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.Info = UNNAMED Object '+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.Movie.Geometry = '+vehicle_path+'\\n\\\n",
    "Traffic.'+str(index)+'.Color = 1.0 0.0 0.0\\n\\\n",
    "Traffic.'+str(index)+'.Basics.Dimension = 4.28 1.82 1.28\\n\\\n",
    "Traffic.'+str(index)+'.Basics.Offset = 0.0 0.0\\n\\\n",
    "Traffic.'+str(index)+'.Basics.Fr12CoM = 2.15\\n\\\n",
    "Traffic.'+str(index)+'.Init.Orientation = 0.0 0.0 0.0\\n\\\n",
    "Traffic.'+str(index)+'.RCSClass = RCS_Car\\n\\\n",
    "Traffic.'+str(index)+'.DetectMask = 1 1\\n\\\n",
    "Traffic.'+str(index)+'.Route = 0 1\\n\\\n",
    "Traffic.'+str(index)+'.Init.Road = 18 R2\\n\\\n",
    "Traffic.'+str(index)+'.Init.v = 1\\n\\\n",
    "Traffic.'+str(index)+'.FreeMotion = 1\\n\\\n",
    "Traffic.'+str(index)+'.UpdRate = 200\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tx.Name =FM_tx_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tx.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tx.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ty.Name =FM_ty_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ty.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ty.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tz.Name =FM_tz_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tz.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tz.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rx.Name =\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rx.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rx.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ry.Name =\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ry.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ry.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rz.Name =FM_rz_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rz.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rz.Offset = 0.0\\n')\n",
    "\n",
    "    \n",
    "ego_coords = ego_info['Translation'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "road_points = []\n",
    "\n",
    "prev_row = None\n",
    "distance = 5.5\n",
    "for index,row in enumerate(ego_coords[::1]):  \n",
    "    if prev_row is None or abs(dist([row[0],row[1],0],prev_row))>1 :\n",
    "        dx = -1*math.sin(ego_info.at[index, 'Yaw'])*distance\n",
    "        dy = math.cos(ego_info.at[index, 'Yaw'])*distance\n",
    "        road_points.append([row[0]+dx,row[1]+dy])\n",
    "        prev_row=[row[0],row[1],0]\n",
    "        \n",
    "        \n",
    "        \n",
    "#pointlist start degree\n",
    "dx = road_points[1][0]-road_points[0][0]\n",
    "dy = road_points[1][1]-road_points[0][1]\n",
    "\n",
    "startDeg = math.degrees(math.atan2(dx, dy))\n",
    "\n",
    "\n",
    "#pointlist end vector\n",
    "dx = ego_coords[-1][0]-ego_coords[-2][0]\n",
    "dy = ego_coords[-1][1]-ego_coords[-2][1]\n",
    "\n",
    "content_lines.append('DrivMan.OW.Active = 1\\n\\\n",
    "DrivMan.OW.Quantities = Time User1 User2 User3 User4\\n\\\n",
    "DrivMan.OW.StartGearNo = 1\\n\\\n",
    "DrivMan.OW.StartVelocity =\\n\\\n",
    "DrivMan.OW.GasMax = 0.5\\n\\\n",
    "DrivMan.OW.RefCh = Time\\n\\\n",
    "DrivMan.OW.ConsiderRoadSigns = 0\\n\\\n",
    "DrivMan.OW.sRoute.Offset = 0\\n\\\n",
    "DrivMan.OW.Time.Name = t[s]\\n\\\n",
    "DrivMan.OW.Time.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User1.Name = x\\n\\\n",
    "DrivMan.OW.User1.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User1.Offset = 0.0\\n\\\n",
    "DrivMan.OW.User2.Name = y\\n\\\n",
    "DrivMan.OW.User2.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User2.Offset = 0.0\\n\\\n",
    "DrivMan.OW.User3.Name = yaw\\n\\\n",
    "DrivMan.OW.User3.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User3.Offset = 0.0\\n\\\n",
    "DrivMan.OW.User4.Name = -\\n\\\n",
    "DrivMan.OW.User4.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User4.Offset = 0.0\\n\\\n",
    "DrivMan.OW.FName = '+EGO_PROFILE_NAME+'\\n\\\n",
    "ErrorClass.0.Action = abort\\n\\\n",
    "ErrorClass.0.Save = 0\\n\\\n",
    "ErrorClass.0.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.1.Action = abort\\n\\\n",
    "ErrorClass.1.Save = 0\\n\\\n",
    "ErrorClass.1.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.2.Action = abort\\n\\\n",
    "ErrorClass.2.Save = 0\\n\\\n",
    "ErrorClass.2.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.3.Action = abort\\n\\\n",
    "ErrorClass.3.Save = 0\\n\\\n",
    "ErrorClass.3.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.4.Action = abort\\n\\\n",
    "ErrorClass.4.Save = 0\\n\\\n",
    "ErrorClass.4.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.5.Action = abort\\n\\\n",
    "ErrorClass.5.Save = 0\\n\\\n",
    "ErrorClass.5.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.6.Action = abort\\n\\\n",
    "ErrorClass.6.Save = 0\\n\\\n",
    "ErrorClass.6.WarningLimit = 10 5\\n\\\n",
    "ErrorClass.7.Action = abort\\n\\\n",
    "ErrorClass.7.Save = 0\\n\\\n",
    "ErrorClass.7.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.10.Action = abort\\n\\\n",
    "ErrorClass.10.Save = 0\\n\\\n",
    "ErrorClass.10.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.11.Action = abort\\n\\\n",
    "ErrorClass.11.Save = 0\\n\\\n",
    "ErrorClass.11.WarningLimit = 3 5\\n\\\n",
    "Road.FileIdent = IPGRoad 8.0\\n\\\n",
    "Road.LibVersion = 8.1\\n\\\n",
    "Road.Country = DEU\\n\\\n",
    "Road.nLinks = 1\\n\\\n",
    "Road.nJunctions = 0\\n\\\n",
    "Road.nObjects = 149\\n\\\n",
    "Road.nRoutes = 1\\n\\\n",
    "Road.RoadNetworkLength = 595.296984550432\\n\\\n",
    "Road.BBox = -19.5668198180623 547.415304391587 -224.837648089968 34.6179698226834 -11 11\\n\\\n",
    "Road.Route.0.Length = 595.296984550432\\n\\\n",
    "Road.RST.Unit = kmh\\n\\\n",
    "Road.RST = 50 100 130 30 70 30 0 -1\\n\\\n",
    "Road.Movie = 0.2 1 0.01 1.5 1.5 1 1\\n\\\n",
    "Road.PathMode = -1\\n\\\n",
    "Road.Link.0.ID = 0\\n\\\n",
    "Road.Link.0.Junctions = -1 -1 -2 -1\\n\\\n",
    "Road.Link.0.Node0 = 0 0 0 '+str(startDeg)+'\\n\\\n",
    "Road.Link.0.RST = countryroad\\n\\\n",
    "Road.Link.0.RL.ID = 1\\n\\\n",
    "Road.Link.0.Seg.0.ID = 5\\n\\\n",
    "Road.Link.0.Seg.0.Type = PointList\\n\\\n",
    "Road.Link.0.Seg.0.Param =  '+str(dx)+' '+str(dy)+' 1 0 0 0 0 0\\n\\\n",
    "Road.Link.0.Seg.0.PointList:\\n')\n",
    "\n",
    "#append road pointlist\n",
    "obj_id=5\n",
    "pointlist = []\n",
    "pointlist.append('# t[s] x y yaw -\\n')\n",
    "counter = 0\n",
    "for index,row in enumerate(ego_coords[::1]):\n",
    "    pointlist.append('  %f %f %f %f %f\\n'%(counter*time_between_records,row[0],row[1],ego_info.at[index, 'Yaw'],0))\n",
    "    counter += 1\n",
    "\n",
    "    \n",
    "with open(EGO_PROFILE_PATH, 'w') as f:\n",
    "    for item in pointlist:\n",
    "        f.write(\"%s\" % item)\n",
    "        \n",
    "        \n",
    "pointlist = ''\n",
    "\n",
    "        \n",
    "        \n",
    "##extending road\n",
    "d0 = 500 #road extension distance\n",
    "\n",
    "\n",
    "# at the end\n",
    "#m = (road_points[-1][1]-road_points[-2][1])/(road_points[-1][0]-road_points[-2][0])\n",
    "dx = road_points[-2][0]-road_points[-1][0]#dx = d0/math.sqrt(1+m**2)\n",
    "dy = road_points[-2][1]-road_points[-1][1]#dy = m*dx\n",
    "road_points.append([road_points[-1][0]-dx*100,road_points[-1][1]-dy*100])\n",
    "\n",
    "# at the beginning\n",
    "#m = (road_points[0][1]-road_points[1][1])/(road_points[0][0]-road_points[1][0])\n",
    "dx = road_points[0][0]-road_points[1][0]#d0/math.sqrt(1+m**2)\n",
    "dy = road_points[0][1]-road_points[1][1]#m*dx\n",
    "#road_points = [[road_points[0][0]+dx*100,road_points[0][1]+dy*100]] + road_points\n",
    "    \n",
    "for row in road_points:\n",
    "    obj_id +=  1\n",
    "    pointlist = pointlist + '\t'+str(row[0])+' '+str(row[1])+'\\n'\n",
    "    \n",
    "content_lines.append(pointlist)    \n",
    "    \n",
    "content_lines.append('Road.Link.0.LaneSection.0.ID = '+str(obj_id+1)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.Start = 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.0.ID = '+str(obj_id+2)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.0 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.0.ARP = '+str(obj_id+5)+' '+str(obj_id+6)+' '+str(obj_id+7)+' '+str(obj_id+8)+' '+str(obj_id+9)+' '+str(obj_id+10)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.1.ID = '+str(obj_id+13)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.1 = 0 0.75 0.75 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.1.ARP = '+str(obj_id+16)+' '+str(obj_id+17)+' '+str(obj_id+18)+' '+str(obj_id+19)+' '+str(obj_id+20)+' '+str(obj_id+21)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.2.ID = '+str(obj_id+24)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.2 = 0 1.5 1.5 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.2.ARP = '+str(obj_id+27)+' '+str(obj_id+28)+' '+str(obj_id+29)+' '+str(obj_id+30)+' '+str(obj_id+31)+' '+str(obj_id+32)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.3.ID = '+str(obj_id+34)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.3 = 0 1.5 1.5 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.3.ARP = '+str(obj_id+37)+' '+str(obj_id+38)+' '+str(obj_id+39)+' '+str(obj_id+40)+' '+str(obj_id+41)+' '+str(obj_id+51)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.4.ID = '+str(obj_id+44)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.4 = 0 0.75 0.75 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.4.ARP = '+str(obj_id+47)+' '+str(obj_id+48)+' '+str(obj_id+49)+' '+str(obj_id+50)+' '+str(obj_id+51)+' '+str(obj_id+52)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.5.ID = '+str(obj_id+55)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.5 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.5.ARP = '+str(obj_id+58)+' '+str(obj_id+59)+' '+str(obj_id+60)+' '+str(obj_id+61)+' '+str(obj_id+62)+' '+str(obj_id+63)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.6.ID = '+str(obj_id+66)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.6 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.6.ARP = '+str(obj_id+69)+' '+str(obj_id+70)+' '+str(obj_id+71)+' '+str(obj_id+72)+' '+str(obj_id+73)+' '+str(obj_id+74)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.7.ID = '+str(obj_id+77)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.7 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.7.ARP = '+str(obj_id+80)+' '+str(obj_id+81)+' '+str(obj_id+82)+' '+str(obj_id+83)+' '+str(obj_id+84)+' '+str(obj_id+85)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.8.ID = '+str(obj_id+88)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.8 = 0 1 1 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.8.ARP = '+str(obj_id+91)+' '+str(obj_id+92)+' '+str(obj_id+93)+' '+str(obj_id+94)+' '+str(obj_id+95)+' '+str(obj_id+96)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.9.ID = '+str(obj_id+98)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.9 = 0 2.5 2.5 5 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.0.ID = '+str(obj_id+101)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.0 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.0.ARP = '+str(obj_id+104)+' '+str(obj_id+105)+' '+str(obj_id+106)+' '+str(obj_id+107)+' '+str(obj_id+108)+' '+str(obj_id+109)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.1.ID = '+str(obj_id+112)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.1 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.1.ARP = '+str(obj_id+115)+' '+str(obj_id+116)+' '+str(obj_id+117)+' '+str(obj_id+118)+' '+str(obj_id+119)+' '+str(obj_id+120)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.2.ID = '+str(obj_id+123)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.2 = 0 1 1 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.2.ARP = '+str(obj_id+126)+' '+str(obj_id+127)+' '+str(obj_id+128)+' '+str(obj_id+129)+' '+str(obj_id+130)+' '+str(obj_id+131)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.3.ID = '+str(obj_id+133)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.3 = 0 2.5 2.5 5 0 0 0\\n\\\n",
    "Road.LanePath.0 = '+str(obj_id+11)+' '+str(obj_id+2)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.1 = '+str(obj_id+22)+' '+str(obj_id+13)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.2 = '+str(obj_id+33)+' '+str(obj_id+24)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.3 = '+str(obj_id+43)+' '+str(obj_id+34)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.4 = '+str(obj_id+53)+' '+str(obj_id+44)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.5 = '+str(obj_id+64)+' '+str(obj_id+55)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.6 = '+str(obj_id+75)+' '+str(obj_id+66)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.7 = '+str(obj_id+86)+' '+str(obj_id+77)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.8 = '+str(obj_id+97)+' '+str(obj_id+88)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.9 = '+str(obj_id+110)+' '+str(obj_id+101)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.10 = '+str(obj_id+121)+' '+str(obj_id+112)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.11 = '+str(obj_id+132)+' '+str(obj_id+123)+' 0.25 10 0.1 0.1\\n\\\n",
    "Route.0.ID = '+str(obj_id+137)+'\\n\\\n",
    "Route.0.Name = Route_0\\n\\\n",
    "Route.0.DrvPath.ID = '+str(obj_id+138)+'\\n\\\n",
    "Route.0.DrvPath:\\n\\\n",
    "\t'+str(obj_id+110)+'\\n\\\n",
    "Road.RL.1.RoadMarking.0.ID = '+str(obj_id+136)+' '+str(obj_id+1)+'\\n\\\n",
    "Road.RL.1.RoadMarking.0 = 0 0 0 1 0 0 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.0.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.1.ID = '+str(obj_id+122)+' '+str(obj_id+112)+'\\n\\\n",
    "Road.RL.1.RoadMarking.1 = 0 0 0 1 0 -1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.1.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.2.ID = '+str(obj_id+111)+' '+str(obj_id+101)+'\\n\\\n",
    "Road.RL.1.RoadMarking.2 = 0 0 0 1 0 -1 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.2.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.3.ID = '+str(obj_id+87)+' '+str(obj_id+77)+'\\n\\\n",
    "Road.RL.1.RoadMarking.3 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.3.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.4.ID = '+str(obj_id+76)+' '+str(obj_id+66)+'\\n\\\n",
    "Road.RL.1.RoadMarking.4 = 0 0 0 1 0 1 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.4.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.5.ID = '+str(obj_id+65)+' '+str(obj_id+55)+'\\n\\\n",
    "Road.RL.1.RoadMarking.5 = 0 0 0 1 0 1 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.5.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.6.ID = '+str(obj_id+54)+' '+str(obj_id+44)+'\\n\\\n",
    "Road.RL.1.RoadMarking.6 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.6.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.7.ID = '+str(obj_id+23)+' '+str(obj_id+13)+'\\n\\\n",
    "Road.RL.1.RoadMarking.7 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.7.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.8.ID = '+str(obj_id+12)+' '+str(obj_id+2)+'\\n\\\n",
    "Road.RL.1.RoadMarking.8 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.8.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.MaxUsedObjId = '+str(obj_id+150)+'\\n\\\n",
    "Road.VhclStartPos = 0 0 0\\n\\\n",
    "Road.VhclRoute = Route_0\\n\\\n",
    "Road.RouteId = 0\\n\\\n",
    "Env.StartTime.Year = 2019\\n\\\n",
    "Env.StartTime.Month = 1\\n\\\n",
    "Env.StartTime.Day = 1\\n\\\n",
    "Env.StartTime.Hour = 12\\n\\\n",
    "Env.StartTime.Min = 0\\n\\\n",
    "Env.StartTime.Sec = 0\\n\\\n",
    "Env.StartTime.DeltaUTC = 0.0\\n\\\n",
    "Env.GNav.Active = 0\\n\\\n",
    "Env.Temperature = 20.0\\n\\\n",
    "Env.AirDensity = 1.205\\n\\\n",
    "Env.AirPressure = 1.013\\n\\\n",
    "Env.AirHumidity = 60\\n\\\n",
    "Env.SolarRadiation = 400.0\\n\\\n",
    "Env.RainRate = 0.0\\n\\\n",
    "Env.VisRangeInFog = 1000.0\\n\\\n",
    "Env.Wind.Kind = none\\n\\\n",
    "Env.Wind.Velocity = 0.0\\n\\\n",
    "Env.Wind.Angle = 0.0\\n\\\n",
    "Env.Sun.Position = geographicDefinition\\n\\\n",
    "Env.Sun.Azimuth = 180.0\\n\\\n",
    "Env.Sun.Elevation = 45.0\\n\\\n",
    "Env.Kind = Generic\\n\\\n",
    "Env.Temp.Offset_Elev = -0.0065\\n\\\n",
    "Env.Temp.Offset_sRoad.Amplify = 1.0\\n\\\n",
    "Env.Temp.Offset_sRoad.On = 0\\n\\\n",
    "Env.Temp.Offset_Time.Amplify = 1.0\\n\\\n",
    "Env.Temp.Offset_Time.On = 1\\n\\\n",
    "Env.Temp.Offset_Time:\\n\\\n",
    "\t0.0 -2.0\\n\\\n",
    "\t3.0 -2.5\\n\\\n",
    "\t6.0 -2.7\\n\\\n",
    "\t7.5 -2.7\\n\\\n",
    "\t9.0 -2.5\\n\\\n",
    "\t10.0 -2.3\\n\\\n",
    "\t11.0 -1.6\\n\\\n",
    "\t12.0 0.0\\n\\\n",
    "\t13.0 1.4\\n\\\n",
    "\t14.0 2.1\\n\\\n",
    "\t15.5 2.5\\n\\\n",
    "\t17.0 2.2\\n\\\n",
    "\t18.0 1.7\\n\\\n",
    "\t19.0 1.1\\n\\\n",
    "\t20.0 0.2\\n\\\n",
    "\t21.0 -0.6\\n\\\n",
    "\t22.0 -1.1\\n\\\n",
    "\t23.0 -1.6\\n\\\n",
    "\t24.0 -2.0\\n\\\n",
    "Driver.ParamIdent = IPGDriver 5\\n\\\n",
    "Driver.Mode = std\\n\\\n",
    "Driver.Long.DrivMaxSpeed = 0\\n\\\n",
    "Driver.Long.CruisingSpeed = 150\\n\\\n",
    "Driver.CornerCutCoef = 0.5\\n\\\n",
    "Driver.ConsiderTraffic = 1\\n\\\n",
    "Driver.Traffic.TimeGapMin = 1.8\\n\\\n",
    "Driver.Traffic.TimeGapMax = 5.0\\n\\\n",
    "Driver.Traffic.DistMin = 6\\n\\\n",
    "Driver.Traffic.DistMax = 250\\n\\\n",
    "Driver.Traffic.EcoCoef = 0.75\\n\\\n",
    "Driver.Traffic.Overtake = 0\\n\\\n",
    "Driver.Traffic.Overtake_Rate = 1\\n\\\n",
    "Driver.Traffic.Overtake_dSpeedMin = 10\\n\\\n",
    "Driver.Long.dtAccBrake = 0.5\\n\\\n",
    "Driver.Long.axMax = 3.0\\n\\\n",
    "Driver.Long.axMin = -4.0\\n\\\n",
    "Driver.Long.ayMax = 4.0\\n\\\n",
    "Driver.Long.GGExp:\\n\\\n",
    "\t50 1.0 1.0\\n\\\n",
    "Driver.Long.DevMax = 0.0\\n\\\n",
    "Driver.Long.tReact = 0.0\\n\\\n",
    "Driver.Long.TractionControl = 1\\n\\\n",
    "Driver.DecShift.UseBrakePark = 0\\n\\\n",
    "Driver.DecShift.tSwitchGear = 1.0\\n\\\n",
    "Driver.DecShift.nEngine.Limits:\\n\\\n",
    "\t1500 4000\\n\\\n",
    "Driver.DecShift.nEngine.Shift:\\n\\\n",
    "\t2000 3000\\n\\\n",
    "Driver.Lat.DevMax = 0.0\\n\\\n",
    "Driver.Lat.tReact = 0.0\\n\\\n",
    "Driver.Knowl.Long.tActionMin = 4\\n\\\n",
    "Driver.Knowl.Lat.StWhlAngleMax = 630\\n\\\n",
    "Driver.Knowl.Lat.StWhlAngleVelMax = 500\\n\\\n",
    "Driver.Knowl.Lat.StWhlAngleAccMax = 3000\\n\\\n",
    "Driver.Learn.VehicleLimits.TestRun =\\n\\\n",
    "Driver.Learn.VehicleLimits.Date = 0\\n\\\n",
    "Driver.Learn.ControllerDyn.TestRun =\\n\\\n",
    "Driver.Learn.ControllerDyn.Date = 0\\n\\\n",
    "Driver.Learn.MaxSpeed.TestRun =\\n\\\n",
    "Driver.Learn.MaxSpeed.Date = 0\\n\\\n",
    "Driver.Learn.Remember = 0\\n\\\n",
    "Driver.Learn.Friction = 1.0\\n\\\n",
    "Driver.Knowl.Long.tPreviewBra = 0.6\\n\\\n",
    "Driver.Knowl.Long.tPreviewAcc = 1.5\\n\\\n",
    "Driver.Knowl.Lat.tPreview = 0.8\\n\\\n",
    "Driver.Learn.NEng_S = 1\\n')\n",
    "\n",
    "\n",
    "with open(TESTRUN_PATH, 'w') as f:\n",
    "    for item in content_lines:\n",
    "        f.write(\"%s\" % item)\n",
    "        \n",
    "print(f'Saved files to: {TESTRUN_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 2.8.15-0ubuntu0.16.04.1 Copyright (c) 2000-2018 the FFmpeg developers\r\n",
      "  built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.10) 20160609\r\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv\r\n",
      "  libavutil      54. 31.100 / 54. 31.100\r\n",
      "  libavcodec     56. 60.100 / 56. 60.100\r\n",
      "  libavformat    56. 40.101 / 56. 40.101\r\n",
      "  libavdevice    56.  4.100 / 56.  4.100\r\n",
      "  libavfilter     5. 40.101 /  5. 40.101\r\n",
      "  libavresample   2.  1.  0 /  2.  1.  0\r\n",
      "  libswscale      3.  1.101 /  3.  1.101\r\n",
      "  libswresample   1.  2.101 /  1.  2.101\r\n",
      "  libpostproc    53.  3.100 / 53.  3.100\r\n",
      "\u001b[0;36m[mjpeg @ 0x10daf80] \u001b[0mChangeing bps to 8\r\n",
      "Input #0, concat, from '/home/itiv/Desktop/lyft-kaggle-dataset/train//img_list.txt':\r\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\r\n",
      "    Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 1224x1024 [SAR 1:1 DAR 153:128], 25 tbr, 25 tbn, 25 tbc\r\n",
      "File '/home/itiv/Desktop/lyft-kaggle-dataset/train/CarMaker/video-scene-10-standard.mp4' already exists. Overwrite ? [y/N] "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "## optional create video from camera data\n",
    "#temp_path = LYFT_DATASET_ROOT+'/temp'\n",
    "#if not os.path.exists(temp_path):\n",
    "#    os.mkdir(temp_path)\n",
    "\n",
    "img_list = []\n",
    "\n",
    "sample_token = scene['first_sample_token']\n",
    "counter = 0\n",
    "while sample_token is not '':\n",
    "    sample = level5data.get('sample', sample_token)\n",
    "    sample_data = level5data.get('sample_data', sample['data']['CAM_FRONT'])\n",
    "    img_list.append('file '+LYFT_DATASET_ROOT+sample_data['filename'])\n",
    "    #copyfile(LYFT_DATASET_ROOT+sample_data['filename'],temp_path+'/img_'+str(counter)+'.jpeg')\n",
    "    counter += 1\n",
    "    sample_token = sample['next']\n",
    "\n",
    "    \n",
    "img_list_path = LYFT_DATASET_ROOT+'/img_list.txt'\n",
    "video_path = LYFT_DATASET_ROOT+'CarMaker/video-'+TESTRUN_ID+'.mp4'\n",
    "with open(img_list_path, 'w') as f:\n",
    "    for item in img_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    \n",
    "!ffmpeg -f concat -r 5 -safe 0 -i $img_list_path -r 5 -c:v libx264 -pix_fmt yuv420p $video_path\n",
    "    \n",
    "print('Video saved to: '+video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lyft_detector]",
   "language": "python",
   "name": "conda-env-lyft_detector-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
