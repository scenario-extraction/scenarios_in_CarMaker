{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Lyft-Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set vars\n",
    "LYFT_DATASET_ROOT = '/home/itiv/Desktop/lyft-kaggle-dataset/train/'\n",
    "CONFIG_DIR = \"./Lyft-Detector/second.pytorch/second/configs/nuscenes/\"\n",
    "MODEL_DIR = './Lyft-Detector/second.pytorch/second/model/'\n",
    "MODEL = 'middle' #small,middle,large\n",
    "VERSION = \"v1.0-trainval\" #v1.0-test for test-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 7.9 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.3 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "#### load ground truth data\n",
    "# Load the SDK\n",
    "%matplotlib inline\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "\n",
    "# Load the dataset\n",
    "# Adjust the dataroot parameter below to point to your local dataset path.\n",
    "# The correct dataset path contains at least the following four folders (or similar): images, lidar, maps, v1.0.1-train\n",
    "level5data = LyftDataset(data_path=LYFT_DATASET_ROOT, json_path=LYFT_DATASET_ROOT+'/data', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create pkl files\n",
    "def create_pkl(scene_num):\n",
    "    scene = level5data.scene[scene_num]\n",
    "    scene_token = scene['token']\n",
    "    version = \"v1.0-trainval\"\n",
    "    !python Lyft-Detector/second.pytorch/second/create_data.py nuscenes_data_prep --root_path=$LYFT_DATASET_ROOT  --version=$version --dataset_name=\"NuScenesDataset\" --scene_token=$scene_token --max_sweeps=10\n",
    "\n",
    "def set_config_file(scene_num,model):\n",
    "    import numpy as np\n",
    "    from second.protos import pipeline_pb2\n",
    "    from google.protobuf import text_format\n",
    "    scene = level5data.scene[scene_num]\n",
    "    scene_token = scene['token']\n",
    "    config_path = CONFIG_DIR+'/all.pp.lowa_'+model+'_range.config'\n",
    "    info_path = LYFT_DATASET_ROOT+'/infos_'+scene_token+'.pkl'\n",
    "\n",
    "    config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "    with open(config_path, \"r\") as f:\n",
    "        proto_str = f.read()\n",
    "        text_format.Merge(proto_str, config)\n",
    "    config.train_input_reader.dataset.kitti_info_path = info_path\n",
    "    config.train_input_reader.dataset.kitti_root_path = LYFT_DATASET_ROOT\n",
    "\n",
    "    config.train_input_reader.preprocess.database_sampler.database_info_path = info_path\n",
    "\n",
    "    config.eval_input_reader.dataset.kitti_info_path = info_path\n",
    "    config.eval_input_reader.dataset.kitti_root_path = LYFT_DATASET_ROOT\n",
    "\n",
    "    config_text = text_format.MessageToString(config)\n",
    "    with open(config_path, \"w\") as f:\n",
    "        f.write(config_text)\n",
    "\n",
    "    print('Paths set in config file')\n",
    "def track(scene_num,model,net):\n",
    "    #model: small,middle,range\n",
    "    scene = level5data.scene[scene_num]\n",
    "    scene_token = scene['token']\n",
    "    \n",
    "    config_path = CONFIG_DIR+'/all.pp.lowa_'+model+'_range.config'\n",
    "    ckpt_path= MODEL_DIR+net\n",
    "    #if model == 'small':\n",
    "    #    ckpt_path= MODEL_DIR+'/model_standard/voxelnet-48698.tckpt'\n",
    "    #elif model == 'middle':\n",
    "    #    ckpt_path = MODEL_DIR+'/model_middle_range/voxelnet-374148.tckpt'\n",
    "    #else:\n",
    "    #    ckpt_path = ''\n",
    "\n",
    "    info_path = LYFT_DATASET_ROOT+'/infos_'+scene_token+'.pkl'\n",
    "    root_path = LYFT_DATASET_ROOT\n",
    "    result_path = LYFT_DATASET_ROOT\n",
    "    version = \"v1.0-trainval\"\n",
    "\n",
    "    print('Detecting...this might take several minutes...')\n",
    "    !python ./Lyft-Detector/second.pytorch/second/detect.py detect --scene_token=$scene_token --config_path=$config_path --ckpt_path=$ckpt_path --info_path=$info_path --root_path=$root_path --result_path=$result_path\n",
    "    print('Tracking...this might take several minutes...')\n",
    "    detection_file = result_path+'/detections_'+scene_token+'.json'\n",
    "    !python ./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py track --save_root=$root_path --version=$version --detection_file=$detection_file --data_root=$root_path\n",
    "    \n",
    "    ## generate output\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from pyquaternion import Quaternion\n",
    "    import numpy as np\n",
    "    import math\n",
    "    import operator\n",
    "    from operator import add\n",
    "    from scipy.stats import beta\n",
    "    from collections import Counter\n",
    "    import os\n",
    "    import random\n",
    "\n",
    "    scene = level5data.scene[scene_num]\n",
    "    scene_token = scene['token']\n",
    "\n",
    "    tracking_file = LYFT_DATASET_ROOT+'/tracking_results_'+scene_token+'.json'\n",
    "\n",
    "    with open(tracking_file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    tracking_ids = []\n",
    "    sample_token = scene['first_sample_token']\n",
    "    timestamp = 0\n",
    "    for index in range(scene['nbr_samples']):\n",
    "        sample = level5data.get('sample', sample_token)\n",
    "        for detection_dict in data['results'][sample_token]:\n",
    "            if not int(detection_dict['tracking_id']) in tracking_ids:\n",
    "                tracking_ids.append(int(detection_dict['tracking_id']))\n",
    "            else:\n",
    "                counter += 1\n",
    "        sample_token = sample['next']\n",
    "        if sample_token is '':\n",
    "            break\n",
    "\n",
    "    tracking_ids.sort()            \n",
    "\n",
    "    print(f'Extracted {len(tracking_ids)} tracks')\n",
    "\n",
    "\n",
    "    index = range(scene['nbr_samples'])\n",
    "    columns = [\"Car \"+str(x) for x in tracking_ids]\n",
    "\n",
    "\n",
    "    traffic_coords = pd.DataFrame(index=index, columns=columns)\n",
    "    traffic_coords = traffic_coords.astype(object)\n",
    "\n",
    "    traffic_orientation = pd.DataFrame(index=index, columns=columns)\n",
    "    traffic_orientation = traffic_orientation.astype(object)\n",
    "\n",
    "    traffic_sizes = pd.DataFrame(index=index, columns=columns)\n",
    "    traffic_sizes = traffic_sizes.astype(object)\n",
    "\n",
    "    columns = ['Timestamp','Translation','Yaw']\n",
    "    ego_info = pd.DataFrame(index=index, columns=columns)\n",
    "    ego_info = ego_info.astype(object)\n",
    "\n",
    "\n",
    "    translation_offset = None\n",
    "\n",
    "    sample_token = scene['first_sample_token']\n",
    "    for index in range(scene['nbr_samples']):\n",
    "        sample = level5data.get('sample', sample_token)\n",
    "        sample_data = level5data.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "\n",
    "        ego_pose = level5data.get('ego_pose', sample_data['ego_pose_token'])\n",
    "\n",
    "        if translation_offset is None:\n",
    "            translation_offset = ego_pose['translation']\n",
    "\n",
    "        ego_info.at[index, 'Timestamp'] = ego_pose['timestamp']\n",
    "        ego_info.at[index, 'Yaw'] = Quaternion(ego_pose['rotation']).yaw_pitch_roll[0]\n",
    "        ego_info.at[index, 'Translation'] = list(map(operator.sub,ego_pose['translation'],translation_offset))\n",
    "        #filter pedestrians and bicycles    \n",
    "        for detection_dict in data['results'][sample_token]:\n",
    "            if not (detection_dict['tracking_name'] == 'bicycle' or detection_dict['tracking_name'] == 'pedestrian'):\n",
    "                traffic_coords.at[index, 'Car '+detection_dict['tracking_id']] =  list(map(operator.sub,detection_dict['translation'],translation_offset))\n",
    "                traffic_orientation.at[index, 'Car '+detection_dict['tracking_id']] = Quaternion(detection_dict['rotation']).yaw_pitch_roll[0]\n",
    "                traffic_sizes.at[index, 'Car '+detection_dict['tracking_id']] = detection_dict['size']\n",
    "        sample_token = sample['next']\n",
    "        if sample_token is '':\n",
    "            break\n",
    "\n",
    "    #filter short occurence traffic <1s\n",
    "    for index,entrys in traffic_coords.count().iteritems():\n",
    "        if entrys < 5:\n",
    "            traffic_coords.drop(index,axis=1,inplace=True)\n",
    "            traffic_sizes.drop(index,axis=1,inplace=True)\n",
    "            traffic_orientation.drop(index,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    def dist(l1,l2):\n",
    "        d = math.sqrt((l1[0]-l2[0])**2+(l1[1]-l2[1])**2+(l1[2]-l2[2])**2)\n",
    "        return d\n",
    "\n",
    "    #filter intersection traffic with ego\n",
    "    for (columnName, columnData) in traffic_coords.iteritems():\n",
    "        for index,item in enumerate(traffic_coords[columnName]):\n",
    "            if type(ego_info.at[index, 'Translation']) is list and type(item) is list and dist(item,ego_info.at[index, 'Translation']) < 1:\n",
    "                traffic_coords.drop(columnName,axis=1,inplace=True)\n",
    "                traffic_sizes.drop(columnName,axis=1,inplace=True)\n",
    "                traffic_orientation.drop(columnName,axis=1,inplace=True)\n",
    "                print(f'dropped {columnName}')\n",
    "                break;\n",
    "\n",
    "\n",
    "    #interpolate short NaNs\n",
    "    for (columnName, columnData) in traffic_coords.iteritems():\n",
    "        for index,item in enumerate(traffic_coords[columnName]):\n",
    "            if type(item) is list and len(traffic_coords[columnName])>index+1 and type(traffic_coords[columnName][index+1]) is not list:\n",
    "                for step in range(10):\n",
    "                    if len(traffic_coords[columnName])>index+1+step and type(traffic_coords[columnName][index+1+step]) is list:\n",
    "                        v = list(map(operator.sub, traffic_coords[columnName][index+1+step],item))\n",
    "                        traffic_coords[columnName][index+1] = list(map(operator.add, item, [x / (step+1) for x in v]))\n",
    "                        traffic_orientation[columnName][index+1] = (traffic_orientation[columnName][index+1+step]-traffic_orientation[columnName][index])/(step+1)\n",
    "                        traffic_sizes[columnName][index+1] = traffic_sizes[columnName][index]\n",
    "                        #print(f'{item} {traffic_coords[columnName][index+1]} {traffic_coords[columnName][index+1+step]}')\n",
    "                        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def plotVal(x):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        from scipy import stats\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        sns.distplot(x);\n",
    "\n",
    "\n",
    "    #suppress random orientation changes \n",
    "    #driving vehicle: orientation according to direction\n",
    "    #standing vehicle: orientation according to most detected\n",
    "\n",
    "    dt = 0.2 #Periodendauer\n",
    "    for (columnName, columnData) in traffic_orientation.iteritems():\n",
    "\n",
    "        traffic_speed = []\n",
    "        moving = False\n",
    "        for index,item in enumerate(traffic_coords[columnName]):\n",
    "            if type(item) is list and len(traffic_coords[columnName])>index+1 and type(traffic_coords[columnName][index+1]) is list:\n",
    "                traffic_speed.append(abs(dist(item,traffic_coords[columnName][index+1])/dt))\n",
    "            else:\n",
    "                traffic_speed.append(np.nan)\n",
    "\n",
    "        prev_orientation = None\n",
    "        not_moving_orientations = []\n",
    "        not_moving_start_index = 0\n",
    "        for index,item in enumerate(traffic_speed):\n",
    "\n",
    "            if moving and (abs(item) < 1.5 or math.isnan(item)):\n",
    "                moving = False\n",
    "                not_moving_orientations = []\n",
    "                not_moving_start_index = index\n",
    "            elif not moving and (abs(item) > 2 or math.isnan(item)): \n",
    "                if len(not_moving_orientations) > 1:\n",
    "                    orientation,_ = (Counter(not_moving_orientations).most_common(1)[0])\n",
    "                    if not math.isnan(orientation):\n",
    "                        for idx in range(index-not_moving_start_index):\n",
    "                            traffic_orientation[columnName][index-idx] = orientation\n",
    "\n",
    "                    #plotVal(not_moving_orientations)\n",
    "                moving = True\n",
    "            if not math.isnan(item):\n",
    "                if index >= len(traffic_speed)-5:\n",
    "                    if prev_orientation is not None:\n",
    "                        traffic_orientation[columnName][index] = prev_orientation\n",
    "                elif moving and type(traffic_coords[columnName][index]) is list and type(traffic_coords[columnName][index+5]) is list:\n",
    "                    v = list(map(operator.sub,traffic_coords[columnName][index],traffic_coords[columnName][index+5]))\n",
    "                    yaw = math.atan2(v[1],v[0])-np.pi\n",
    "                    traffic_orientation[columnName][index] = yaw #---> TODO!!!!!!!!!!!!!!!!!!!!\n",
    "                elif moving and type(traffic_coords[columnName][index]) is list and type(traffic_coords[columnName][index+1]) is not list and prev_orientation is not None:\n",
    "                    traffic_orientation[columnName][index] = prev_orientation\n",
    "                elif not moving:\n",
    "                    not_moving_orientations.append(round(traffic_orientation[columnName][index],1))\n",
    "\n",
    "                prev_orientation = traffic_orientation[columnName][index]\n",
    "            else:\n",
    "                traffic_orientation[columnName][index] = prev_orientation\n",
    "\n",
    "    ## create result_json_dict #####\n",
    "\n",
    "    gt_dict = {'samples':[]}\n",
    "\n",
    "    #iterate over rows\n",
    "    for index, row in traffic_coords.iterrows():\n",
    "        #iterate over columns\n",
    "        sample_dict = {'token':'frame_'+str(index),'timestamp':index*0.2,'anns':[]}\n",
    "\n",
    "        for colIndex in range(len(row)):\n",
    "            if type(traffic_coords.iloc[index,colIndex]) is list:\n",
    "                ann_dict = {'instance':colIndex,'translation':traffic_coords.iloc[index,colIndex],'size':traffic_sizes.iloc[index,colIndex],'rotation':traffic_orientation.iloc[index,colIndex]}\n",
    "                sample_dict['anns'].append(ann_dict)\n",
    "        gt_dict['samples'].append(sample_dict)\n",
    "\n",
    "\n",
    "    def dist(l1,l2):\n",
    "        d = math.sqrt((l1[0]-l2[0])**2+(l1[1]-l2[1])**2+(l1[2]-l2[2])**2)\n",
    "        return d\n",
    "    \n",
    "    ##########\n",
    "\n",
    "    CM_PROJECT_DIR =  LYFT_DATASET_ROOT+'/CarMaker'#'C://CM_Projects//maneuver_simu'\n",
    "    TESTRUN_DIR = CM_PROJECT_DIR+'/TestRun'#CM_PROJECT_DIR+'//Data//TestRun'\n",
    "    SIMINPUT_DIR = CM_PROJECT_DIR+'/SimInput/'#CM_PROJECT_DIR+'//SimInput'\n",
    "\n",
    "    GROUND_TRUTH_DIR = CM_PROJECT_DIR+'/gt_data/'  #only for eval\n",
    "\n",
    "    if not os.path.exists(CM_PROJECT_DIR):\n",
    "        os.mkdir(CM_PROJECT_DIR)\n",
    "    if not os.path.exists(TESTRUN_DIR):\n",
    "        os.mkdir(TESTRUN_DIR)\n",
    "    if not os.path.exists(SIMINPUT_DIR):\n",
    "        os.mkdir(SIMINPUT_DIR)\n",
    "    if not os.path.exists(GROUND_TRUTH_DIR):\n",
    "        os.mkdir(GROUND_TRUTH_DIR)\n",
    "\n",
    "    SCENE_NUM = scene_num\n",
    "\n",
    "    TESTRUN_ID = 'scene-'+str(SCENE_NUM)+'-'+MODEL\n",
    "    TESTRUN_NAME = f'//testrun_{TESTRUN_ID}'\n",
    "    TESTRUN_PATH = TESTRUN_DIR+TESTRUN_NAME\n",
    "    TRAFFIC_PROFILE_NAME = f'traffic_profile_{TESTRUN_ID}.txt'\n",
    "    TRAFFIC_PROFILE_PATH = SIMINPUT_DIR+TRAFFIC_PROFILE_NAME\n",
    "    EGO_PROFILE_NAME = f'ego_profile_{TESTRUN_ID}.txt'\n",
    "    EGO_PROFILE_PATH = SIMINPUT_DIR+EGO_PROFILE_NAME\n",
    "\n",
    "    gt_data_name = f'gt_data_{TESTRUN_ID}.json'\n",
    "    with open(GROUND_TRUTH_DIR+gt_data_name, 'w') as fp:\n",
    "        json.dump(gt_dict, fp)\n",
    "\n",
    "\n",
    "\n",
    "    content_lines = []\n",
    "    content_lines.append('#INFOFILE1.1 - Do not remove this line!\\n\\\n",
    "FileIdent = CarMaker-TestRun 8\\n\\\n",
    "FileCreator = CarMaker 8.1 2019-11-07\\n\\\n",
    "Description:\\n\\\n",
    "Vehicle = UserVehicle_MyCar\\n\\\n",
    "Trailer =\\n\\\n",
    "Tire.0 =\\n\\\n",
    "Tire.1 =\\n\\\n",
    "Tire.2 =\\n\\\n",
    "Tire.3 =\\n\\\n",
    "Snapshot.TimeLimit =\\n\\\n",
    "Snapshot.DistLimit =\\n\\\n",
    "VehicleLoad.0.mass = 0\\n\\\n",
    "VehicleLoad.0.pos = 0 0 0\\n\\\n",
    "VehicleLoad.1.mass = 0\\n\\\n",
    "VehicleLoad.1.pos = 0 0 0\\n\\\n",
    "VehicleLoad.2.mass = 0\\n\\\n",
    "VehicleLoad.2.pos = 0 0 0\\n\\\n",
    "VehicleLoad.3.mass = 0\\n\\\n",
    "VehicleLoad.3.pos = 0 0 0\\n\\\n",
    "TrailerLoad.0.mass = 0\\n\\\n",
    "TrailerLoad.0.pos = 0 0 0\\n\\\n",
    "TrailerLoad.1.mass = 0\\n\\\n",
    "TrailerLoad.1.pos = 0 0 0\\n\\\n",
    "TrailerLoad.2.mass = 0\\n\\\n",
    "TrailerLoad.2.pos = 0 0 0\\n')\n",
    "\n",
    "    #ego maneuver for every 10th coord\n",
    "\n",
    "    time_between_records = 0.2 \n",
    "\n",
    "    start_vel = 0#ego_vel[0]\n",
    "    man_counter = 1\n",
    "    #ego_man = []\n",
    "    #for vel in ego_vel[::10]:\n",
    "    #    ego_man.append('DrivMan.'+str(man_counter)+'.TimeLimit = '+str(10*time_between_records)+'\\n\\\n",
    "    #DrivMan.'+str(man_counter)+'.LongDyn = VelControl '+str(vel*3.6)+' 0.0 1.0 0 1 0\\n\\\n",
    "    #DrivMan.'+str(man_counter)+'.LatDyn = Driver 0\\n')\n",
    "    #    man_counter += 1\n",
    "\n",
    "           # +str(start_vel)+\n",
    "    content_lines.append('DrivMan.Init.Velocity = 0\\n\\\n",
    "DrivMan.Init.SteerAng = 0\\n\\\n",
    "DrivMan.Init.GearNo = 0\\n\\\n",
    "DrivMan.Init.LaneOffset = 0\\n\\\n",
    "DrivMan.Init.OperatorActive = 1\\n\\\n",
    "DrivMan.Init.OperatorState = drive\\n\\\n",
    "DrivMan.VhclOperator.Kind = IPGOperator 1\\n\\\n",
    "DrivMan.nDMan = '+str(man_counter)+'\\n')\n",
    "\n",
    "    content_lines.append('DrivMan.0.TimeLimit = '+str(time_between_records*(len(ego_info)-1))+'\\n\\\n",
    "DrivMan.0.LongDyn = Stop 2.0 0\\n\\\n",
    "DrivMan.0.LatDyn = Driver 0\\n')\n",
    "\n",
    "\n",
    "    #write traffic profile file\n",
    "\n",
    "    traffic_profile = []\n",
    "    traffic_profile.append('# Time')\n",
    "    for index,col in enumerate(traffic_coords):\n",
    "        traffic_profile.append(' FM_tx_%d FM_ty_%d FM_tz_%d FM_rz_%d' % (index,index,index,index))\n",
    "    traffic_profile.append('\\n')    \n",
    "\n",
    "\n",
    "    prev_row = None\n",
    "    for time_index, row in traffic_coords.iterrows():\n",
    "        traffic_profile.append('%f'%(time_index*time_between_records))\n",
    "\n",
    "        for car_index,coords in enumerate(row):\n",
    "            if type(coords) is list:\n",
    "                traffic_profile.append(' %f %f %f %f'%(coords[0],coords[1],0.6,traffic_orientation.iloc[time_index,car_index]))\n",
    "            else:\n",
    "                traffic_profile.append(' %f %f %f %f'%(0,0,-100,0))\n",
    "\n",
    "        prev_row = row\n",
    "        traffic_profile.append('\\n') \n",
    "\n",
    "\n",
    "\n",
    "    with open(TRAFFIC_PROFILE_PATH, 'w') as f:\n",
    "        for item in traffic_profile:\n",
    "            f.write(\"%s\" % item)\n",
    "\n",
    "\n",
    "    traffic_counter = 0   \n",
    "    traffic_counter = len(traffic_coords.columns)\n",
    "    content_lines.append('Traffic.IFF.FName = SimInput/'+TRAFFIC_PROFILE_NAME+'\\n\\\n",
    "Traffic.IFF.Time.Name = Time\\n\\\n",
    "Traffic.N = %d\\n\\\n",
    "Traffic.SpeedUnit = ms\\n'%traffic_counter)\n",
    "\n",
    "\n",
    "    #get average sizes of vehicle\n",
    "\n",
    "    traffic_sizes_avr = []\n",
    "    for (columnName, columnData) in traffic_sizes.iteritems():\n",
    "        counter = 0\n",
    "        l_sum = 0\n",
    "        for size in columnData.values:\n",
    "            if isinstance(size, list):\n",
    "                counter += 1\n",
    "                l_sum += size[1]\n",
    "        traffic_sizes_avr.append(l_sum/counter)\n",
    "\n",
    "    small_car = ['Audi_TT_2015.mobj','Citroen_C3_2015.mobj','Honda_Fit_2015.mobj'] #l<4m\n",
    "    medium_car = ['Audi_A4AllRoad_2016.mobj','Audi_A7_2018.mobj','BMW_5_2017.mobj','Honda_CivicTypeR_2018.mobj','MB_AClass_2018.mobj','MB_CClass_2015.mobj','Jaguar_FType_2017.mobj'] #l<5m\n",
    "    large_car = ['Chevrolet_Silverado1500_2013.mobj','Chrysler_Pacifica_2016.mobj','Dodge_GrandCaravan_2011.mobj','LandRover_RangeRover_2014.mobj','MB_XClass_2018.mobj'] #l<6m\n",
    "    van = ['Ford_Transit_2014.mobj','MB_Sprinter_2013.mobj','MB_Vito_2014.mobj','VW_T6_2016.mobj','VW_Transporter_2016.mobj'] #l<10m\n",
    "    bus_truck = ['Coach.mobj','Euro_ConcreteMixer.mobj','Iveco_EurotechLN2_1992.mobj','MAN_TGS_2012.mobj','MB_Actros_1996.mobj','MB_Atego_2013_Move.mobj'] #l>10m\n",
    "\n",
    "\n",
    "\n",
    "    for index,col in enumerate(traffic_coords): \n",
    "\n",
    "        vehicle_path = '3D/Vehicles/'\n",
    "\n",
    "        if traffic_sizes_avr[index]<4:\n",
    "            vehicle_path = vehicle_path+small_car[random.randrange(0,len(small_car),1)]\n",
    "        elif traffic_sizes_avr[index]<5:\n",
    "            vehicle_path = vehicle_path+medium_car[random.randrange(0,len(medium_car),1)]\n",
    "        elif traffic_sizes_avr[index]<6:\n",
    "            vehicle_path = vehicle_path+large_car[random.randrange(0,len(large_car),1)]\n",
    "        elif traffic_sizes_avr[index]<10:\n",
    "            vehicle_path = vehicle_path+van[random.randrange(0,len(van),1)]   \n",
    "        elif traffic_sizes_avr[index]>10:\n",
    "            vehicle_path = vehicle_path+bus_truck[random.randrange(0,len(bus_truck),1)]   \n",
    "\n",
    "        content_lines.append('Traffic.'+str(index)+'.ObjectKind = Movable\\n\\\n",
    "Traffic.'+str(index)+'.ObjectClass = Car\\n\\\n",
    "Traffic.'+str(index)+'.Name = T'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.Info = UNNAMED Object '+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.Movie.Geometry = '+vehicle_path+'\\n\\\n",
    "Traffic.'+str(index)+'.Color = 1.0 0.0 0.0\\n\\\n",
    "Traffic.'+str(index)+'.Basics.Dimension = 4.28 1.82 1.28\\n\\\n",
    "Traffic.'+str(index)+'.Basics.Offset = 0.0 0.0\\n\\\n",
    "Traffic.'+str(index)+'.Basics.Fr12CoM = 2.15\\n\\\n",
    "Traffic.'+str(index)+'.Init.Orientation = 0.0 0.0 0.0\\n\\\n",
    "Traffic.'+str(index)+'.RCSClass = RCS_Car\\n\\\n",
    "Traffic.'+str(index)+'.DetectMask = 1 1\\n\\\n",
    "Traffic.'+str(index)+'.Route = 0 1\\n\\\n",
    "Traffic.'+str(index)+'.Init.Road = 18 R2\\n\\\n",
    "Traffic.'+str(index)+'.Init.v = 1\\n\\\n",
    "Traffic.'+str(index)+'.FreeMotion = 1\\n\\\n",
    "Traffic.'+str(index)+'.UpdRate = 200\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tx.Name =FM_tx_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tx.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tx.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ty.Name =FM_ty_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ty.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ty.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tz.Name =FM_tz_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tz.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_tz.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rx.Name =\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rx.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rx.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ry.Name =\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ry.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_ry.Offset = 0.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rz.Name =FM_rz_'+str(index)+'\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rz.Factor = 1.0\\n\\\n",
    "Traffic.'+str(index)+'.IFF.FM_rz.Offset = 0.0\\n')\n",
    "\n",
    "\n",
    "    ego_coords = ego_info['Translation'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    road_points = []\n",
    "\n",
    "    prev_row = None\n",
    "    distance = 5.5\n",
    "    for index,row in enumerate(ego_coords[::1]):  \n",
    "        if prev_row is None or abs(dist([row[0],row[1],0],prev_row))>1 :\n",
    "            dx = -1*math.sin(ego_info.at[index, 'Yaw'])*distance\n",
    "            dy = math.cos(ego_info.at[index, 'Yaw'])*distance\n",
    "            road_points.append([row[0]+dx,row[1]+dy])\n",
    "            prev_row=[row[0],row[1],0]\n",
    "\n",
    "\n",
    "\n",
    "    #pointlist start degree\n",
    "    dx = road_points[1][0]-road_points[0][0]\n",
    "    dy = road_points[1][1]-road_points[0][1]\n",
    "\n",
    "    startDeg = math.degrees(math.atan2(dx, dy))\n",
    "\n",
    "\n",
    "    #pointlist end vector\n",
    "    dx = ego_coords[-1][0]-ego_coords[-2][0]\n",
    "    dy = ego_coords[-1][1]-ego_coords[-2][1]\n",
    "\n",
    "    content_lines.append('DrivMan.OW.Active = 1\\n\\\n",
    "DrivMan.OW.Quantities = Time User1 User2 User3 User4\\n\\\n",
    "DrivMan.OW.StartGearNo = 1\\n\\\n",
    "DrivMan.OW.StartVelocity =\\n\\\n",
    "DrivMan.OW.GasMax = 0.5\\n\\\n",
    "DrivMan.OW.RefCh = Time\\n\\\n",
    "DrivMan.OW.ConsiderRoadSigns = 0\\n\\\n",
    "DrivMan.OW.sRoute.Offset = 0\\n\\\n",
    "DrivMan.OW.Time.Name = t[s]\\n\\\n",
    "DrivMan.OW.Time.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User1.Name = x\\n\\\n",
    "DrivMan.OW.User1.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User1.Offset = 0.0\\n\\\n",
    "DrivMan.OW.User2.Name = y\\n\\\n",
    "DrivMan.OW.User2.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User2.Offset = 0.0\\n\\\n",
    "DrivMan.OW.User3.Name = yaw\\n\\\n",
    "DrivMan.OW.User3.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User3.Offset = 0.0\\n\\\n",
    "DrivMan.OW.User4.Name = -\\n\\\n",
    "DrivMan.OW.User4.Factor = 1.0\\n\\\n",
    "DrivMan.OW.User4.Offset = 0.0\\n\\\n",
    "DrivMan.OW.FName = '+EGO_PROFILE_NAME+'\\n\\\n",
    "ErrorClass.0.Action = abort\\n\\\n",
    "ErrorClass.0.Save = 0\\n\\\n",
    "ErrorClass.0.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.1.Action = abort\\n\\\n",
    "ErrorClass.1.Save = 0\\n\\\n",
    "ErrorClass.1.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.2.Action = abort\\n\\\n",
    "ErrorClass.2.Save = 0\\n\\\n",
    "ErrorClass.2.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.3.Action = abort\\n\\\n",
    "ErrorClass.3.Save = 0\\n\\\n",
    "ErrorClass.3.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.4.Action = abort\\n\\\n",
    "ErrorClass.4.Save = 0\\n\\\n",
    "ErrorClass.4.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.5.Action = abort\\n\\\n",
    "ErrorClass.5.Save = 0\\n\\\n",
    "ErrorClass.5.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.6.Action = abort\\n\\\n",
    "ErrorClass.6.Save = 0\\n\\\n",
    "ErrorClass.6.WarningLimit = 10 5\\n\\\n",
    "ErrorClass.7.Action = abort\\n\\\n",
    "ErrorClass.7.Save = 0\\n\\\n",
    "ErrorClass.7.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.10.Action = abort\\n\\\n",
    "ErrorClass.10.Save = 0\\n\\\n",
    "ErrorClass.10.WarningLimit = 3 5\\n\\\n",
    "ErrorClass.11.Action = abort\\n\\\n",
    "ErrorClass.11.Save = 0\\n\\\n",
    "ErrorClass.11.WarningLimit = 3 5\\n\\\n",
    "Road.FileIdent = IPGRoad 8.0\\n\\\n",
    "Road.LibVersion = 8.1\\n\\\n",
    "Road.Country = DEU\\n\\\n",
    "Road.nLinks = 1\\n\\\n",
    "Road.nJunctions = 0\\n\\\n",
    "Road.nObjects = 149\\n\\\n",
    "Road.nRoutes = 1\\n\\\n",
    "Road.RoadNetworkLength = 595.296984550432\\n\\\n",
    "Road.BBox = -19.5668198180623 547.415304391587 -224.837648089968 34.6179698226834 -11 11\\n\\\n",
    "Road.Route.0.Length = 595.296984550432\\n\\\n",
    "Road.RST.Unit = kmh\\n\\\n",
    "Road.RST = 50 100 130 30 70 30 0 -1\\n\\\n",
    "Road.Movie = 0.2 1 0.01 1.5 1.5 1 1\\n\\\n",
    "Road.PathMode = -1\\n\\\n",
    "Road.Link.0.ID = 0\\n\\\n",
    "Road.Link.0.Junctions = -1 -1 -2 -1\\n\\\n",
    "Road.Link.0.Node0 = 0 0 0 '+str(startDeg)+'\\n\\\n",
    "Road.Link.0.RST = countryroad\\n\\\n",
    "Road.Link.0.RL.ID = 1\\n\\\n",
    "Road.Link.0.Seg.0.ID = 5\\n\\\n",
    "Road.Link.0.Seg.0.Type = PointList\\n\\\n",
    "Road.Link.0.Seg.0.Param =  '+str(dx)+' '+str(dy)+' 1 0 0 0 0 0\\n\\\n",
    "Road.Link.0.Seg.0.PointList:\\n')\n",
    "\n",
    "    #append road pointlist\n",
    "    obj_id=5\n",
    "    pointlist = []\n",
    "    pointlist.append('# t[s] x y yaw -\\n')\n",
    "    counter = 0\n",
    "    for index,row in enumerate(ego_coords[::1]):\n",
    "        pointlist.append('  %f %f %f %f %f\\n'%(counter*time_between_records,row[0],row[1],ego_info.at[index, 'Yaw'],0))\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    with open(EGO_PROFILE_PATH, 'w') as f:\n",
    "        for item in pointlist:\n",
    "            f.write(\"%s\" % item)\n",
    "\n",
    "\n",
    "    pointlist = ''\n",
    "\n",
    "\n",
    "\n",
    "    ##extending road\n",
    "    d0 = 500 #road extension distance\n",
    "\n",
    "\n",
    "    # at the end\n",
    "    #m = (road_points[-1][1]-road_points[-2][1])/(road_points[-1][0]-road_points[-2][0])\n",
    "    dx = road_points[-2][0]-road_points[-1][0]#dx = d0/math.sqrt(1+m**2)\n",
    "    dy = road_points[-2][1]-road_points[-1][1]#dy = m*dx\n",
    "    road_points.append([road_points[-1][0]-dx*100,road_points[-1][1]-dy*100])\n",
    "\n",
    "    # at the beginning\n",
    "    #m = (road_points[0][1]-road_points[1][1])/(road_points[0][0]-road_points[1][0])\n",
    "    dx = road_points[0][0]-road_points[1][0]#d0/math.sqrt(1+m**2)\n",
    "    dy = road_points[0][1]-road_points[1][1]#m*dx\n",
    "    #road_points = [[road_points[0][0]+dx*100,road_points[0][1]+dy*100]] + road_points\n",
    "\n",
    "    for row in road_points:\n",
    "        obj_id +=  1\n",
    "        pointlist = pointlist + '\t'+str(row[0])+' '+str(row[1])+'\\n'\n",
    "\n",
    "    content_lines.append(pointlist)    \n",
    "\n",
    "    content_lines.append('Road.Link.0.LaneSection.0.ID = '+str(obj_id+1)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.Start = 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.0.ID = '+str(obj_id+2)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.0 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.0.ARP = '+str(obj_id+5)+' '+str(obj_id+6)+' '+str(obj_id+7)+' '+str(obj_id+8)+' '+str(obj_id+9)+' '+str(obj_id+10)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.1.ID = '+str(obj_id+13)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.1 = 0 0.75 0.75 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.1.ARP = '+str(obj_id+16)+' '+str(obj_id+17)+' '+str(obj_id+18)+' '+str(obj_id+19)+' '+str(obj_id+20)+' '+str(obj_id+21)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.2.ID = '+str(obj_id+24)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.2 = 0 1.5 1.5 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.2.ARP = '+str(obj_id+27)+' '+str(obj_id+28)+' '+str(obj_id+29)+' '+str(obj_id+30)+' '+str(obj_id+31)+' '+str(obj_id+32)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.3.ID = '+str(obj_id+34)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.3 = 0 1.5 1.5 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.3.ARP = '+str(obj_id+37)+' '+str(obj_id+38)+' '+str(obj_id+39)+' '+str(obj_id+40)+' '+str(obj_id+41)+' '+str(obj_id+51)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.4.ID = '+str(obj_id+44)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.4 = 0 0.75 0.75 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.4.ARP = '+str(obj_id+47)+' '+str(obj_id+48)+' '+str(obj_id+49)+' '+str(obj_id+50)+' '+str(obj_id+51)+' '+str(obj_id+52)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.5.ID = '+str(obj_id+55)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.5 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.5.ARP = '+str(obj_id+58)+' '+str(obj_id+59)+' '+str(obj_id+60)+' '+str(obj_id+61)+' '+str(obj_id+62)+' '+str(obj_id+63)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.6.ID = '+str(obj_id+66)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.6 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.6.ARP = '+str(obj_id+69)+' '+str(obj_id+70)+' '+str(obj_id+71)+' '+str(obj_id+72)+' '+str(obj_id+73)+' '+str(obj_id+74)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.7.ID = '+str(obj_id+77)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.7 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.7.ARP = '+str(obj_id+80)+' '+str(obj_id+81)+' '+str(obj_id+82)+' '+str(obj_id+83)+' '+str(obj_id+84)+' '+str(obj_id+85)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.8.ID = '+str(obj_id+88)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.8 = 0 1 1 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.8.ARP = '+str(obj_id+91)+' '+str(obj_id+92)+' '+str(obj_id+93)+' '+str(obj_id+94)+' '+str(obj_id+95)+' '+str(obj_id+96)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.9.ID = '+str(obj_id+98)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneL.9 = 0 2.5 2.5 5 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.0.ID = '+str(obj_id+101)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.0 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.0.ARP = '+str(obj_id+104)+' '+str(obj_id+105)+' '+str(obj_id+106)+' '+str(obj_id+107)+' '+str(obj_id+108)+' '+str(obj_id+109)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.1.ID = '+str(obj_id+112)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.1 = 0 3.5 3.5 0 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.1.ARP = '+str(obj_id+115)+' '+str(obj_id+116)+' '+str(obj_id+117)+' '+str(obj_id+118)+' '+str(obj_id+119)+' '+str(obj_id+120)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.2.ID = '+str(obj_id+123)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.2 = 0 1 1 4 0 0 0\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.2.ARP = '+str(obj_id+126)+' '+str(obj_id+127)+' '+str(obj_id+128)+' '+str(obj_id+129)+' '+str(obj_id+130)+' '+str(obj_id+131)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.3.ID = '+str(obj_id+133)+'\\n\\\n",
    "Road.Link.0.LaneSection.0.LaneR.3 = 0 2.5 2.5 5 0 0 0\\n\\\n",
    "Road.LanePath.0 = '+str(obj_id+11)+' '+str(obj_id+2)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.1 = '+str(obj_id+22)+' '+str(obj_id+13)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.2 = '+str(obj_id+33)+' '+str(obj_id+24)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.3 = '+str(obj_id+43)+' '+str(obj_id+34)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.4 = '+str(obj_id+53)+' '+str(obj_id+44)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.5 = '+str(obj_id+64)+' '+str(obj_id+55)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.6 = '+str(obj_id+75)+' '+str(obj_id+66)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.7 = '+str(obj_id+86)+' '+str(obj_id+77)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.8 = '+str(obj_id+97)+' '+str(obj_id+88)+' 0.25 10 0.1 0.1\\n\\\n",
    "Road.LanePath.9 = '+str(obj_id+110)+' '+str(obj_id+101)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.10 = '+str(obj_id+121)+' '+str(obj_id+112)+' 2 10 0.1 0.1\\n\\\n",
    "Road.LanePath.11 = '+str(obj_id+132)+' '+str(obj_id+123)+' 0.25 10 0.1 0.1\\n\\\n",
    "Route.0.ID = '+str(obj_id+137)+'\\n\\\n",
    "Route.0.Name = Route_0\\n\\\n",
    "Route.0.DrvPath.ID = '+str(obj_id+138)+'\\n\\\n",
    "Route.0.DrvPath:\\n\\\n",
    "    '+str(obj_id+110)+'\\n\\\n",
    "Road.RL.1.RoadMarking.0.ID = '+str(obj_id+136)+' '+str(obj_id+1)+'\\n\\\n",
    "Road.RL.1.RoadMarking.0 = 0 0 0 1 0 0 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.0.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.1.ID = '+str(obj_id+122)+' '+str(obj_id+112)+'\\n\\\n",
    "Road.RL.1.RoadMarking.1 = 0 0 0 1 0 -1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.1.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.2.ID = '+str(obj_id+111)+' '+str(obj_id+101)+'\\n\\\n",
    "Road.RL.1.RoadMarking.2 = 0 0 0 1 0 -1 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.2.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.3.ID = '+str(obj_id+87)+' '+str(obj_id+77)+'\\n\\\n",
    "Road.RL.1.RoadMarking.3 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.3.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.4.ID = '+str(obj_id+76)+' '+str(obj_id+66)+'\\n\\\n",
    "Road.RL.1.RoadMarking.4 = 0 0 0 1 0 1 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.4.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.5.ID = '+str(obj_id+65)+' '+str(obj_id+55)+'\\n\\\n",
    "Road.RL.1.RoadMarking.5 = 0 0 0 1 0 1 0.15 0 2 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.5.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.6.ID = '+str(obj_id+54)+' '+str(obj_id+44)+'\\n\\\n",
    "Road.RL.1.RoadMarking.6 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.6.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.7.ID = '+str(obj_id+23)+' '+str(obj_id+13)+'\\n\\\n",
    "Road.RL.1.RoadMarking.7 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.7.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.RL.1.RoadMarking.8.ID = '+str(obj_id+12)+' '+str(obj_id+2)+'\\n\\\n",
    "Road.RL.1.RoadMarking.8 = 0 0 0 1 0 1 0.15 0 1 0 0 2 4 1 1 0 \"\"\\n\\\n",
    "Road.RL.1.RoadMarking.8.Material.0 = 1.0,1.0,1.0 0 0 0 0 0 0 0 0 0 0 0\\n\\\n",
    "Road.MaxUsedObjId = '+str(obj_id+150)+'\\n\\\n",
    "Road.VhclStartPos = 0 0 0\\n\\\n",
    "Road.VhclRoute = Route_0\\n\\\n",
    "Road.RouteId = 0\\n\\\n",
    "Env.StartTime.Year = 2019\\n\\\n",
    "Env.StartTime.Month = 1\\n\\\n",
    "Env.StartTime.Day = 1\\n\\\n",
    "Env.StartTime.Hour = 12\\n\\\n",
    "Env.StartTime.Min = 0\\n\\\n",
    "Env.StartTime.Sec = 0\\n\\\n",
    "Env.StartTime.DeltaUTC = 0.0\\n\\\n",
    "Env.GNav.Active = 0\\n\\\n",
    "Env.Temperature = 20.0\\n\\\n",
    "Env.AirDensity = 1.205\\n\\\n",
    "Env.AirPressure = 1.013\\n\\\n",
    "Env.AirHumidity = 60\\n\\\n",
    "Env.SolarRadiation = 400.0\\n\\\n",
    "Env.RainRate = 0.0\\n\\\n",
    "Env.VisRangeInFog = 1000.0\\n\\\n",
    "Env.Wind.Kind = none\\n\\\n",
    "Env.Wind.Velocity = 0.0\\n\\\n",
    "Env.Wind.Angle = 0.0\\n\\\n",
    "Env.Sun.Position = geographicDefinition\\n\\\n",
    "Env.Sun.Azimuth = 180.0\\n\\\n",
    "Env.Sun.Elevation = 45.0\\n\\\n",
    "Env.Kind = Generic\\n\\\n",
    "Env.Temp.Offset_Elev = -0.0065\\n\\\n",
    "Env.Temp.Offset_sRoad.Amplify = 1.0\\n\\\n",
    "Env.Temp.Offset_sRoad.On = 0\\n\\\n",
    "Env.Temp.Offset_Time.Amplify = 1.0\\n\\\n",
    "Env.Temp.Offset_Time.On = 1\\n\\\n",
    "Env.Temp.Offset_Time:\\n\\\n",
    "    0.0 -2.0\\n\\\n",
    "    3.0 -2.5\\n\\\n",
    "    6.0 -2.7\\n\\\n",
    "    7.5 -2.7\\n\\\n",
    "    9.0 -2.5\\n\\\n",
    "    10.0 -2.3\\n\\\n",
    "    11.0 -1.6\\n\\\n",
    "    12.0 0.0\\n\\\n",
    "    13.0 1.4\\n\\\n",
    "    14.0 2.1\\n\\\n",
    "    15.5 2.5\\n\\\n",
    "    17.0 2.2\\n\\\n",
    "    18.0 1.7\\n\\\n",
    "    19.0 1.1\\n\\\n",
    "    20.0 0.2\\n\\\n",
    "    21.0 -0.6\\n\\\n",
    "    22.0 -1.1\\n\\\n",
    "    23.0 -1.6\\n\\\n",
    "    24.0 -2.0\\n\\\n",
    "Driver.ParamIdent = IPGDriver 5\\n\\\n",
    "Driver.Mode = std\\n\\\n",
    "Driver.Long.DrivMaxSpeed = 0\\n\\\n",
    "Driver.Long.CruisingSpeed = 150\\n\\\n",
    "Driver.CornerCutCoef = 0.5\\n\\\n",
    "Driver.ConsiderTraffic = 1\\n\\\n",
    "Driver.Traffic.TimeGapMin = 1.8\\n\\\n",
    "Driver.Traffic.TimeGapMax = 5.0\\n\\\n",
    "Driver.Traffic.DistMin = 6\\n\\\n",
    "Driver.Traffic.DistMax = 250\\n\\\n",
    "Driver.Traffic.EcoCoef = 0.75\\n\\\n",
    "Driver.Traffic.Overtake = 0\\n\\\n",
    "Driver.Traffic.Overtake_Rate = 1\\n\\\n",
    "Driver.Traffic.Overtake_dSpeedMin = 10\\n\\\n",
    "Driver.Long.dtAccBrake = 0.5\\n\\\n",
    "Driver.Long.axMax = 3.0\\n\\\n",
    "Driver.Long.axMin = -4.0\\n\\\n",
    "Driver.Long.ayMax = 4.0\\n\\\n",
    "Driver.Long.GGExp:\\n\\\n",
    "    50 1.0 1.0\\n\\\n",
    "Driver.Long.DevMax = 0.0\\n\\\n",
    "Driver.Long.tReact = 0.0\\n\\\n",
    "Driver.Long.TractionControl = 1\\n\\\n",
    "Driver.DecShift.UseBrakePark = 0\\n\\\n",
    "Driver.DecShift.tSwitchGear = 1.0\\n\\\n",
    "Driver.DecShift.nEngine.Limits:\\n\\\n",
    "    1500 4000\\n\\\n",
    "Driver.DecShift.nEngine.Shift:\\n\\\n",
    "    2000 3000\\n\\\n",
    "Driver.Lat.DevMax = 0.0\\n\\\n",
    "Driver.Lat.tReact = 0.0\\n\\\n",
    "Driver.Knowl.Long.tActionMin = 4\\n\\\n",
    "Driver.Knowl.Lat.StWhlAngleMax = 630\\n\\\n",
    "Driver.Knowl.Lat.StWhlAngleVelMax = 500\\n\\\n",
    "Driver.Knowl.Lat.StWhlAngleAccMax = 3000\\n\\\n",
    "Driver.Learn.VehicleLimits.TestRun =\\n\\\n",
    "Driver.Learn.VehicleLimits.Date = 0\\n\\\n",
    "Driver.Learn.ControllerDyn.TestRun =\\n\\\n",
    "Driver.Learn.ControllerDyn.Date = 0\\n\\\n",
    "Driver.Learn.MaxSpeed.TestRun =\\n\\\n",
    "Driver.Learn.MaxSpeed.Date = 0\\n\\\n",
    "Driver.Learn.Remember = 0\\n\\\n",
    "Driver.Learn.Friction = 1.0\\n\\\n",
    "Driver.Knowl.Long.tPreviewBra = 0.6\\n\\\n",
    "Driver.Knowl.Long.tPreviewAcc = 1.5\\n\\\n",
    "Driver.Knowl.Lat.tPreview = 0.8\\n\\\n",
    "Driver.Learn.NEng_S = 1\\n')\n",
    "\n",
    "\n",
    "    with open(TESTRUN_PATH, 'w') as f:\n",
    "        for item in content_lines:\n",
    "            f.write(\"%s\" % item)\n",
    "\n",
    "    print(f'Saved files to: {TESTRUN_PATH}')\n",
    "    \n",
    "    \n",
    "def outputvideo(scene_num):\n",
    "    import os\n",
    "    from shutil import copyfile\n",
    "\n",
    "    ## optional create video from camera data\n",
    "    #temp_path = LYFT_DATASET_ROOT+'/temp'\n",
    "    #if not os.path.exists(temp_path):\n",
    "    #    os.mkdir(temp_path)\n",
    "\n",
    "    img_list = []\n",
    "    scene = level5data.scene[scene_num]\n",
    "    scene_token = scene['token']\n",
    "    sample_token = scene['first_sample_token']\n",
    "    counter = 0\n",
    "    while sample_token is not '':\n",
    "        sample = level5data.get('sample', sample_token)\n",
    "        sample_data = level5data.get('sample_data', sample['data']['CAM_FRONT'])\n",
    "        img_list.append('file '+LYFT_DATASET_ROOT+sample_data['filename'])\n",
    "        #copyfile(LYFT_DATASET_ROOT+sample_data['filename'],temp_path+'/img_'+str(counter)+'.jpeg')\n",
    "        counter += 1\n",
    "        sample_token = sample['next']\n",
    "\n",
    "\n",
    "    img_list_path = LYFT_DATASET_ROOT+'/img_list.txt'\n",
    "    video_path = LYFT_DATASET_ROOT+'CarMaker/video-'+str(scene_num)+'.mp4'\n",
    "    with open(img_list_path, 'w') as f:\n",
    "        for item in img_list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    !ffmpeg -f concat -r 5 -safe 0 -i $img_list_path -r 5 -c:v libx264 -pix_fmt yuv420p $video_path\n",
    "\n",
    "    print('Video saved to: '+video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load tracking data\n",
    "\n",
    "def loadDetectionDict(scene_num,config):\n",
    "    import json\n",
    "\n",
    "    #scene: index of scene\n",
    "    #config: small,middle,large\n",
    "\n",
    "    det_dict_path = '/home/itiv/Desktop/lyft-kaggle-dataset/train/CarMaker/gt_data/gt_data_scene-'+str(scene_num)+'-'+config+'.json'\n",
    "    det_dict = json.load(open(det_dict_path))\n",
    "    return det_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ann_in_boundries(ego,ann,config,plot):\n",
    "    from pyquaternion import Quaternion\n",
    "\n",
    "    \n",
    "    \n",
    "    ###TODO!!!!!!!!!!\n",
    "    #detection boundries TODO filter ground truth out of detection boundary!!!\n",
    "    det_bound = [50,50,50,50] #dist to front,right,back,left\n",
    "    if model == 'middle':\n",
    "        det_bound = [100,70,70,70]\n",
    "    elif model == 'large':\n",
    "        det_bound  = [150,100,100,100]\n",
    "\n",
    "    width = det_bound[1]+det_bound[3]\n",
    "    length = det_bound[0]+det_bound[2]\n",
    "    \n",
    "    center_dist = det_bound[0]-length/2 \n",
    "    \n",
    "    ego_yaw = Quaternion(ego['rotation']).yaw_pitch_roll[0]\n",
    "    ego_x_center = ego['translation'][0]\n",
    "    ego_y_center = ego['translation'][1]\n",
    "    \n",
    "    boundary_box_center_x = np.sin(ego_yaw)*center_dist+ego_x_center\n",
    "    boundary_box_center_y = np.sin(ego_yaw)*center_dist+ego_y_center\n",
    "    \n",
    "        \n",
    "    \n",
    "    traffic_yaw = Quaternion(ann['rotation']).yaw_pitch_roll[0]\n",
    "    traffic_x_center = ann['translation'][0]\n",
    "    traffic_y_center = ann['translation'][1]\n",
    "    traffic_width = ann['size'][0]\n",
    "    traffic_height = ann['size'][1]\n",
    "    \n",
    "    ann_rect = []\n",
    "    ego_rect = []\n",
    "    \n",
    "    ann_rect.append([ann['translation'][0],ann['translation'][1],ann['size'][1],ann['size'][0],traffic_yaw])\n",
    "    ego_rect.append([boundary_box_center_x,boundary_box_center_y,length,width,ego_yaw])\n",
    "    \n",
    "    \n",
    "    ann_rect = np.array(ann_rect)\n",
    "    ego_rect = np.array(ego_rect)\n",
    "\n",
    "    \n",
    "    \n",
    "    iou = intersection_over_union(ann_rect,ego_rect,plot)\n",
    "    \n",
    "    print(iou)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def load_ground_truth_data(scene_num,config):\n",
    "    from pyquaternion import Quaternion\n",
    "    import operator\n",
    "    import math\n",
    "\n",
    "\n",
    "    scene = level5data.scene[scene_num]\n",
    "    scene_token = scene['token']\n",
    "\n",
    "    sample_token = scene['first_sample_token']\n",
    "    sample = level5data.get('sample', sample_token)\n",
    "    sample_data = level5data.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "    ego_pose = level5data.get('ego_pose',sample_data['ego_pose_token'])\n",
    "\n",
    "\n",
    "    trans_offset = ego_pose['translation']\n",
    "\n",
    "\n",
    "    gt_dict = {'samples':[]}\n",
    "    plot = True\n",
    "\n",
    "    for index in range(scene['nbr_samples']):\n",
    "        sample = level5data.get('sample', sample_token)\n",
    "\n",
    "        if(math.fmod(index,100) == 0):\n",
    "            plot = True\n",
    "            \n",
    "\n",
    "        sample_token = sample['next']\n",
    "        \n",
    "        #if sample_token == '':\n",
    "         #   print('Finished earlier at: '+str(index))\n",
    "        \n",
    "        sample_dict = {'token':sample_token,'timestamp':sample['timestamp'],'anns':[]}\n",
    "\n",
    "        sample_data = level5data.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "        ego_pose = level5data.get('ego_pose',sample_data['ego_pose_token'])\n",
    "        for ann_token in sample['anns']:\n",
    "            ann = level5data.get('sample_annotation', ann_token)\n",
    "            \n",
    "            if ann_in_boundries(ego_pose,ann,config,plot) and (ann['category_name'] == 'car' or ann['category_name'] == 'bus' or ann['category_name'] == 'construction_vehicle' or ann['category_name'] == 'motorcycle' or ann['category_name'] == 'truck' or ann['category_name'] == 'trailer'):     \n",
    "                yaw = Quaternion(ann['rotation']).yaw_pitch_roll[0]\n",
    "                ann_dict = {'instance':ann['instance_token'],'translation':list(map(operator.sub,ann['translation'],trans_offset)),'size':ann['size'],'rotation':yaw}\n",
    "                sample_dict['anns'].append(ann_dict)\n",
    "\n",
    "        plot = False\n",
    "        gt_dict['samples'].append(sample_dict)\n",
    "        \n",
    "        \n",
    "    return gt_dict\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://arxiv.org/pdf/1603.00831.pdf\n",
    "#\n",
    "#\n",
    "#Multiple Object Tracking Accuracy\n",
    "# ratio of misses in the sequence, computed over the total number of objects present in all frames\n",
    "# ratio of false positives (bounding box with iou < T)\n",
    "# ratio of mismatches (id change)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rect_polygon(x, y, width, height, angle):\n",
    "    from shapely.geometry import Polygon\n",
    "    from shapely.affinity import rotate, translate\n",
    "    import math\n",
    "\n",
    "    \"\"\"Return a shapely Polygon describing the rectangle with centre at\n",
    "    (x, y) and the given width and height, rotated by angle quarter-turns.\n",
    "\n",
    "    \"\"\"\n",
    "    w = width / 2\n",
    "    h = height / 2\n",
    "    p = Polygon([(-w, -h), (w, -h), (w, h), (-w, h)])\n",
    "    return translate(rotate(p, math.degrees(angle)), x, y)\n",
    "\n",
    "\n",
    "def intersection_over_union(rects_a, rects_b,plot=False):\n",
    "    import rtree.index\n",
    "    from shapely.affinity import rotate, translate\n",
    "    from shapely.geometry import Polygon\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "\n",
    "    \"\"\"Calculate the intersection-over-union for every pair of rectangles\n",
    "    in the two arrays.\n",
    "\n",
    "    Arguments:\n",
    "    rects_a: array_like, shape=(M, 5)\n",
    "    rects_b: array_like, shape=(N, 5)\n",
    "        Rotated rectangles, represented as (centre x, centre y, width,\n",
    "        height, rotation in quarter-turns).\n",
    "\n",
    "    Returns:\n",
    "    iou: array, shape=(M, N)\n",
    "        Array whose element i, j is the intersection-over-union\n",
    "        measure for rects_a[i] and rects_b[j].\n",
    "\n",
    "    \"\"\"\n",
    "    m = len(rects_a)\n",
    "    n = len(rects_b)\n",
    "    if m > n:\n",
    "        # More memory-efficient to compute it the other way round and\n",
    "        # transpose.\n",
    "        return intersection_over_union(rects_b, rects_a,plot).T\n",
    "\n",
    "    # Convert rects_a to shapely Polygon objects.\n",
    "    polys_a = [rect_polygon(*r) for r in rects_a]\n",
    "\n",
    "    # Build a spatial index for rects_a.\n",
    "    index_a = rtree.index.Index()\n",
    "    for i, a in enumerate(polys_a):\n",
    "        index_a.insert(i, a.bounds)\n",
    "    \n",
    "    #print((index_a))\n",
    "        \n",
    "    # Find candidate intersections using the spatial index.\n",
    "    iou = np.zeros((m, n))\n",
    "    for j, rect_b in enumerate(rects_b):\n",
    "        b = rect_polygon(*rect_b)\n",
    "        if plot:\n",
    "            x,y = b.exterior.xy\n",
    "            plt.plot(x,y,'g-')\n",
    "        #print(b.bounds)\n",
    "        for i in range(len(polys_a)):#index_a.intersection(b.bounds):\n",
    "            a = polys_a[i]\n",
    "            if(j == 1 and plot):\n",
    "                x,y = a.exterior.xy\n",
    "                plt.plot(x,y,'r-')  \n",
    "            intersection_area = a.intersection(b).area\n",
    "            if intersection_area:\n",
    "                iou[i, j] = intersection_area / a.union(b).area\n",
    "    \n",
    "    if plot and iou[0,0] > 0:\n",
    "        x,y = polys_a[0].exterior.xy\n",
    "        plt.plot(x,y,'r-') \n",
    "    \n",
    "            \n",
    "    return iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_iou_for_scene(gt_dict,det_dict,id_counter_init):\n",
    "    \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    iou_arr = []\n",
    "    gt_obj_id = []\n",
    "    det_obj_id = []\n",
    "\n",
    "    global id_counter\n",
    "    id_counter = id_counter_init\n",
    "    global id_conversion_dict\n",
    "    id_conversion_dict = {}\n",
    "\n",
    "\n",
    "    def instance_token_to_id(token):\n",
    "        global id_counter\n",
    "        global id_conversion_dict\n",
    "        if not token in id_conversion_dict:\n",
    "            id_counter += 1\n",
    "            id_conversion_dict.update( {token : id_counter} )\n",
    "\n",
    "        return id_conversion_dict[token]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for sample_index in range(len(gt_dict['samples'])):\n",
    "\n",
    "        gt_rects = []\n",
    "        gt_ids = []\n",
    "        for anns in gt_dict['samples'][sample_index]['anns']:\n",
    "            rect = [anns['translation'][0],anns['translation'][1],anns['size'][1],anns['size'][0],anns['rotation']]\n",
    "            gt_rects.append(rect)\n",
    "            gt_ids.append(instance_token_to_id(anns['instance']))\n",
    "\n",
    "        det_rects = []\n",
    "        det_ids = []\n",
    "        for anns in det_dict['samples'][sample_index]['anns']:\n",
    "            rect = [anns['translation'][0],anns['translation'][1],anns['size'][1],anns['size'][0],anns['rotation']]\n",
    "            det_rects.append(rect)\n",
    "            det_ids.append(anns['instance'])\n",
    "\n",
    "\n",
    "        gt_obj_id.append(gt_ids)\n",
    "        det_obj_id.append(det_ids)\n",
    "\n",
    "\n",
    "        gt_rects = np.array(gt_rects)\n",
    "        det_rects = np.array(det_rects)\n",
    "\n",
    "\n",
    "        iou_arr.append(intersection_over_union(gt_rects,det_rects,False))\n",
    "\n",
    "        ### returns \n",
    "        #  det det det det det\n",
    "        #gt\n",
    "        #gt\n",
    "        #gt\n",
    "        #gt\n",
    "        #gt\n",
    "        #print(intersection_over_union(gt_rects,det_rects,False))\n",
    "        #print(len(gt_rects))\n",
    "        #print(len(det_rects))\n",
    "\n",
    "\n",
    "\n",
    "    return iou_arr,gt_obj_id,det_obj_id,id_counter\n",
    "\n",
    "\n",
    "    '''\n",
    "    # Convert rects_a to shapely Polygon objects.\n",
    "    polys_gt = [rect_polygon(*r) for r in gt_rects]\n",
    "    # Convert rects_a to shapely Polygon objects.\n",
    "    polys_det = [rect_polygon(*r) for r in det_rects]\n",
    "    \n",
    "    \n",
    "    for a in polys_gt:\n",
    "        x,y = a.exterior.xy\n",
    "        plt.plot(x,y,'g-')\n",
    "    for b in polys_det:\n",
    "        x,y = b.exterior.xy\n",
    "        plt.plot(x,y,'r-')\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sum of gt\n",
    "## sum of misses\n",
    "## sum of false positive\n",
    "## sum of mismatch\n",
    "\n",
    "## dist = 1 - iou\n",
    "\n",
    "IOU_TRESHOLD = 0.5\n",
    "\n",
    "\n",
    "def get_MOTA_Acc(iou_arr,gt_obj_id,det_obj_id):\n",
    "    import motmetrics as mm\n",
    "    import numpy as np\n",
    "\n",
    "    # Create an accumulator that will be updated during each frame\n",
    "    acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "    for index,iou in enumerate(iou_arr):\n",
    "\n",
    "        \n",
    "        dist = np.subtract(np.ones(iou.shape),iou)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        for i, r in enumerate(dist):\n",
    "            for j, c in enumerate(r):\n",
    "                if dist[i,j] > (1-IOU_TRESHOLD):\n",
    "                    dist[i,j] = np.nan\n",
    "\n",
    "        # Call update once for per frame. For now, assume distances between\n",
    "        # frame objects / hypotheses are given.\n",
    "        acc.update(\n",
    "            gt_obj_id[index],                     # Ground truth objects in this frame\n",
    "            det_obj_id[index],                  # Detector hypotheses in this frame\n",
    "            dist.tolist()\n",
    "        )\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "15991 instance,\n",
      "8 sensor,\n",
      "128 calibrated_sensor,\n",
      "149072 ego_pose,\n",
      "148 log,\n",
      "148 scene,\n",
      "18634 sample,\n",
      "149072 sample_data,\n",
      "539765 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 6.3 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 1.8 seconds.\n",
      "======\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 4,\n",
       " 6,\n",
       " 12,\n",
       " 25,\n",
       " 30,\n",
       " 32,\n",
       " 41,\n",
       " 45,\n",
       " 46,\n",
       " 48,\n",
       " 61,\n",
       " 70,\n",
       " 76,\n",
       " 79,\n",
       " 80,\n",
       " 83,\n",
       " 84,\n",
       " 87,\n",
       " 104,\n",
       " 108,\n",
       " 114,\n",
       " 120,\n",
       " 130,\n",
       " 134,\n",
       " 141,\n",
       " 142,\n",
       " 146,\n",
       " 153,\n",
       " 174,\n",
       " 175,\n",
       " 176]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### get test scenes!\n",
    "# Load the SDK\n",
    "%matplotlib inline\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "\n",
    "# Load the dataset\n",
    "# Adjust the dataroot parameter below to point to your local dataset path.\n",
    "# The correct dataset path contains at least the following four folders (or similar): images, lidar, maps, v1.0.1-train\n",
    "level5datalyft = LyftDataset(data_path='/home/itiv/Desktop/lyft-dataset/', json_path='/home/itiv/Desktop/lyft-dataset/'+'/v1.02-train', verbose=True)\n",
    "\n",
    "## extract test scenes...\n",
    "counter = 0\n",
    "test_scene_index = []\n",
    "for kaggleindex,kagglescene in enumerate(level5data.scene):\n",
    "    for index,lyftscene in enumerate(level5datalyft.scene):\n",
    "        if kagglescene['name'] == lyftscene['name']:\n",
    "            counter += 1\n",
    "            break\n",
    "        elif index == len(level5datalyft.scene)-1:\n",
    "            #not found:\n",
    "            counter += 1\n",
    "            test_scene_index.append(kaggleindex)\n",
    "\n",
    "\n",
    "test_scene_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scene = level5data.scene[test_scene_index[5]]\n",
    "scene_token = scene['token']\n",
    "\n",
    "level5data.render_scene(scene_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Paths set in config file\n",
      "Detecting...this might take several minutes...\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_CUDA_DRIVER=/usr/lib/x86_64-linux-gnu/libcuda.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "Tracking...this might take several minutes...\n",
      "track nuscenes\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 8.1 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.2 seconds.\n",
      "======\n",
      "Loaded results from /home/itiv/Desktop/lyft-kaggle-dataset/train//detections_da4ed9e02f64c544f4f1f10c6738216dcb0e6b0d50952e158e5589854af9f100.json. Found detections for 126 samples.\n",
      "  0%|                                                   | 0/126 [00:00<?, ?it/s]./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py:116: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function roty failed at nopython mode lowering due to: \n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 123:\n",
      "def roty(t):\n",
      "    <source elided>\n",
      "                     [0,  1,  0],\n",
      "                     [-s, 0,  c]])\n",
      "                     ^\n",
      "\n",
      "[1] During: lowering \"$0.24 = build_list(items=[Var($0.14, main.py:121), Var($0.18, main.py:122), Var($0.23, main.py:123)])\" at ./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py (123)\n",
      "  @jit\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"roty\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 117:\n",
      "@jit       \n",
      "def roty(t):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 117:\n",
      "@jit       \n",
      "def roty(t):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "100%|█████████████████████████████████████████| 126/126 [00:02<00:00, 46.47it/s]\n",
      "Total Tracking took: 2.618 for 126 frames or 48.1 FPS\n",
      "Extracted 219 tracks\n",
      "dropped Car 338\n",
      "Saved files to: /home/itiv/Desktop/lyft-kaggle-dataset/train//CarMaker/TestRun//testrun_scene-0-middle\n",
      "ffmpeg version 2.8.15-0ubuntu0.16.04.1 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.10) 20160609\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv\n",
      "  libavutil      54. 31.100 / 54. 31.100\n",
      "  libavcodec     56. 60.100 / 56. 60.100\n",
      "  libavformat    56. 40.101 / 56. 40.101\n",
      "  libavdevice    56.  4.100 / 56.  4.100\n",
      "  libavfilter     5. 40.101 /  5. 40.101\n",
      "  libavresample   2.  1.  0 /  2.  1.  0\n",
      "  libswscale      3.  1.101 /  3.  1.101\n",
      "  libswresample   1.  2.101 /  1.  2.101\n",
      "  libpostproc    53.  3.100 / 53.  3.100\n",
      "\u001b[0;36m[mjpeg @ 0x19f6f80] \u001b[0mChangeing bps to 8\n",
      "Input #0, concat, from '/home/itiv/Desktop/lyft-kaggle-dataset/train//img_list.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 1920x1080 [SAR 1:1 DAR 16:9], 25 tbr, 25 tbn, 25 tbc\n",
      "File '/home/itiv/Desktop/lyft-kaggle-dataset/train/CarMaker/video-0.mp4' already exists. Overwrite ? [y/N] ^C\n",
      "Video saved to: /home/itiv/Desktop/lyft-kaggle-dataset/train/CarMaker/video-0.mp4\n",
      "4\n",
      "Paths set in config file\n",
      "Detecting...this might take several minutes...\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_CUDA_DRIVER=/usr/lib/x86_64-linux-gnu/libcuda.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "Tracking...this might take several minutes...\n",
      "track nuscenes\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 6.9 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.3 seconds.\n",
      "======\n",
      "Loaded results from /home/itiv/Desktop/lyft-kaggle-dataset/train//detections_ccc0662a4dbc63f589358ac9589b677f6d4165a128af93baf26619711c1d7b4f.json. Found detections for 126 samples.\n",
      "  0%|                                                   | 0/126 [00:00<?, ?it/s]./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py:116: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function roty failed at nopython mode lowering due to: \n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 123:\n",
      "def roty(t):\n",
      "    <source elided>\n",
      "                     [0,  1,  0],\n",
      "                     [-s, 0,  c]])\n",
      "                     ^\n",
      "\n",
      "[1] During: lowering \"$0.24 = build_list(items=[Var($0.14, main.py:121), Var($0.18, main.py:122), Var($0.23, main.py:123)])\" at ./Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py (123)\n",
      "  @jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"roty\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 117:\n",
      "@jit       \n",
      "def roty(t):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/itiv/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"Lyft-Tracker/mahalanobis_3d_multi_object_tracking/main.py\", line 117:\n",
      "@jit       \n",
      "def roty(t):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "Extracted 151 tracks\n",
      "dropped Car 248\n",
      "Saved files to: /home/itiv/Desktop/lyft-kaggle-dataset/train//CarMaker/TestRun//testrun_scene-4-middle\n",
      "ffmpeg version 2.8.15-0ubuntu0.16.04.1 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.10) 20160609\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv\n",
      "  libavutil      54. 31.100 / 54. 31.100\n",
      "  libavcodec     56. 60.100 / 56. 60.100\n",
      "  libavformat    56. 40.101 / 56. 40.101\n",
      "  libavdevice    56.  4.100 / 56.  4.100\n",
      "  libavfilter     5. 40.101 /  5. 40.101\n",
      "  libavresample   2.  1.  0 /  2.  1.  0\n",
      "  libswscale      3.  1.101 /  3.  1.101\n",
      "  libswresample   1.  2.101 /  1.  2.101\n",
      "  libpostproc    53.  3.100 / 53.  3.100\n",
      "\u001b[0;36m[mjpeg @ 0x13e9f80] \u001b[0mChangeing bps to 8\n",
      "Input #0, concat, from '/home/itiv/Desktop/lyft-kaggle-dataset/train//img_list.txt':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 1920x1080 [SAR 1:1 DAR 16:9], 25 tbr, 25 tbn, 25 tbc\n",
      "File '/home/itiv/Desktop/lyft-kaggle-dataset/train/CarMaker/video-4.mp4' already exists. Overwrite ? [y/N] ^C\n",
      "Video saved to: /home/itiv/Desktop/lyft-kaggle-dataset/train/CarMaker/video-4.mp4\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-752a31c493b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mset_config_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moutputvideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-80d6506cf79d>\u001b[0m in \u001b[0;36mset_config_file\u001b[0;34m(scene_num, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mproto_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_input_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkitti_info_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_input_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkitti_root_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLYFT_DATASET_ROOT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mMerge\u001b[0;34m(text, message, allow_unknown_extension, allow_field_number, descriptor_pool, allow_unknown_field)\u001b[0m\n\u001b[1;32m    700\u001b[0m       \u001b[0mallow_field_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m       \u001b[0mdescriptor_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescriptor_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       allow_unknown_field=allow_unknown_field)\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mMergeLines\u001b[0;34m(lines, message, allow_unknown_extension, allow_field_number, descriptor_pool, allow_unknown_field)\u001b[0m\n\u001b[1;32m    768\u001b[0m                    \u001b[0mdescriptor_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescriptor_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                    allow_unknown_field=allow_unknown_field)\n\u001b[0;32m--> 770\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mMergeLines\u001b[0;34m(self, lines, message)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;34m\"\"\"Merges a text representation of a protocol message into a message.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_multiple_scalars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ParseOrMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_ParseOrMerge\u001b[0;34m(self, lines, message)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAtEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeField\u001b[0;34m(self, tokenizer, message)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0mmerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Proto field is unknown.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeMessageField\u001b[0;34m(self, tokenizer, message, field)\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAtEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseErrorPreviousToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected \"%s\".'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_map_entry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeField\u001b[0;34m(self, tokenizer, message)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0mmerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Proto field is unknown.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeMessageField\u001b[0;34m(self, tokenizer, message, field)\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAtEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseErrorPreviousToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected \"%s\".'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_map_entry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeField\u001b[0;34m(self, tokenizer, message)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0mmerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Proto field is unknown.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeMessageField\u001b[0;34m(self, tokenizer, message, field)\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAtEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseErrorPreviousToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected \"%s\".'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_map_entry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeField\u001b[0;34m(self, tokenizer, message)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0mmerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Proto field is unknown.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeMessageField\u001b[0;34m(self, tokenizer, message, field)\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAtEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseErrorPreviousToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected \"%s\".'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_map_entry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeField\u001b[0;34m(self, tokenizer, message)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0mmerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Proto field is unknown.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_MergeMessageField\u001b[0;34m(self, tokenizer, message, field)\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0mend_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m       \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m       \u001b[0mend_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mConsume\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0mParseError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mcouldn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \"\"\"\n\u001b[0;32m-> 1287\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTryConsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected \"%s\".'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mTryConsume\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \"\"\"\n\u001b[1;32m   1273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNextToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36mNextToken\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SkipWhitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_more_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lyft_detector/lib/python3.6/site-packages/google/protobuf/text_format.py\u001b[0m in \u001b[0;36m_SkipWhitespace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_PopLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_whitespace_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "      \n",
    "import motmetrics as mm\n",
    "import numpy as np  \n",
    "from datetime import datetime\n",
    "\n",
    "models = ['middle']\n",
    "nets = ['/model_middle_range/voxelnet-374148.tckpt']\n",
    "\n",
    "##create pkl\n",
    "for scene_num in test_scene_index:\n",
    "#    create_pkl(scene_num)\n",
    "    for index,model in enumerate(models):\n",
    "        print(scene_num)\n",
    "        set_config_file(scene_num,model)\n",
    "        track(scene_num,model,nets[index])\n",
    "    #outputvideo(scene_num)\n",
    "\n",
    "print('###########eval#############')        \n",
    "for index,model in enumerate(models):\n",
    "    iou_arr = []\n",
    "    gt_ids = []\n",
    "    det_ids = []\n",
    "    id_counter = 0\n",
    "    accs = []\n",
    "    for scene_num in test_scene_index:\n",
    "        print(f'analyzing scene: {scene_num}')\n",
    "        det_dict = loadDetectionDict(scene_num,model)\n",
    "        gt_dict = load_ground_truth_data(scene_num,model)\n",
    "        scene_iou_arr,scene_gt_ids,scene_det_ids,id_counter_val = get_iou_for_scene(gt_dict,det_dict,id_counter)\n",
    "        id_counter = id_counter_val\n",
    "        #accs.append(get_MOTA_Acc(scene_iou_arr,scene_gt_ids,scene_det_ids))\n",
    "        det_ids.extend(scene_det_ids)\n",
    "        gt_ids.extend(scene_gt_ids)\n",
    "        iou_arr.extend(scene_iou_arr)\n",
    "        \n",
    "    acc = get_MOTA_Acc(iou_arr,gt_ids,det_ids)\n",
    "\n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name=model)\n",
    "    print(summary)\n",
    "    \n",
    "    now = datetime.now() # current date and time\n",
    "    date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    \n",
    "    with open('EvaluationResults.txt', \"a\") as resultFile:\n",
    "        resultFile.write(\"#### \"+str(date_time)+' ###')\n",
    "        resultFile.write(\"Net: \"+nets[index])\n",
    "\n",
    "    \n",
    "    summary.to_csv('EvaluationResults.txt', sep='\\t', mode='a',index=True)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing scene: 30\n",
      "            idf1       idp       idr    recall  precision  num_unique_objects  \\\n",
      "middle  0.683364  0.738997  0.635521  0.687401   0.799323                  94   \n",
      "\n",
      "        mostly_tracked  partially_tracked  mostly_lost  num_false_positives  \\\n",
      "middle              27                 46           21                  652   \n",
      "\n",
      "        num_misses  num_switches  num_fragmentations      mota      motp  \n",
      "middle        1181            27                  54  0.507676  0.179149  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### single scene analysis\n",
    "\n",
    "iou_arr = []\n",
    "gt_ids = []\n",
    "det_ids = []\n",
    "id_counter = 0\n",
    "\n",
    "\n",
    "scene_num = 30\n",
    "model = 'middle'\n",
    "\n",
    "print(f'analyzing scene: {scene_num}')\n",
    "det_dict = loadDetectionDict(scene_num,model)\n",
    "gt_dict = load_ground_truth_data(scene_num,model)\n",
    "scene_iou_arr,scene_gt_ids,scene_det_ids,id_counter_val = get_iou_for_scene(gt_dict,det_dict,id_counter)\n",
    "id_counter = id_counter_val\n",
    "#accs.append(get_MOTA_Acc(scene_iou_arr,scene_gt_ids,scene_det_ids))\n",
    "det_ids.extend(scene_det_ids)\n",
    "gt_ids.extend(scene_gt_ids)\n",
    "iou_arr.extend(scene_iou_arr)\n",
    "\n",
    "acc = get_MOTA_Acc(iou_arr,gt_ids,det_ids)\n",
    "\n",
    "mh = mm.metrics.create()\n",
    "summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name=model)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lyft_detector]",
   "language": "python",
   "name": "conda-env-lyft_detector-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
