Application

1. Daten aus "Radarsensor" fuer alle Objekte und Zeitpunkte
	- Abstand (Nearest Point p)
	- Winkel (Noarest Point alpha, theta)
	- Rechtfertigung: Radar erkennt ungefaehre Richtung (alpha, theta) und absoluten Abstand (p). 
	- Mit dieser Information sind auch x, y, z eindeutig bestimmt. Berechnung theoretisch: r und x aus theta und p. y und z aus alpha und r.
	- Verwende erstmal einfach x, y, z aus Sensor.
	- Daraus: (x, y, z)_Radar in (x, y, z)_aus_Kamerasicht_vorne und (x, y, z)_aus_Kamerasicht_hinten umrechnen:
		(x, y, z)_aus_Kamerasicht = (x, y, z)_Radar - (x, y, z)_Kamera
	- Daraus: "Detektionsintervalle" bestimmen und fuer jedes Detektionsintervall ein neues Objekt definieren. -> Anzahl Objekte erhoeht sich evtl.
		Festhalten, welche "Detektionsobjekte" bzw. "Detektionsintervalle" mit welchen Original-Objekten korrespondieren
		Detektionsbereich: 200m vor und 200m hinter Ego in x-Richtung, also ca. 404m insgesamt
2. Aus allen Fotos alle Boundingboxen bestimmen (ID der erkannten Objekte ist an diesem Punkt noch unbekannt)
Zwischenergebnis: Je Kamera eine Tabelle mit Boundingboxen und zugehoerigen Timestamps
3. Zuordnung ID -> Boundingbox
	- Unterscheidung: x >= x_Kamera_vorne und x <= x_Kamera_hinten
	- Fuer jeden der Radarwerte in Detektionsintervallen bestimmen, wo sich diese theoretisch im Foto befinden muessten
		Mit x_aus_Kamerasicht_Real, y_aus_Kamerasicht_Real, z_aus_Kamerasicht_Real, c_Hoehe und c_Breite: y_theoretisch_Foto und z_theoretisch_Foto ausrechnen:
		y_theoretisch_Foto = y_aus_Kamerasicht_Real / (c_width * x_aus_Kamerasicht_Real)
		z_theoretisch_Foto = z_aus_Kamerasicht_Real / (c_height * x_aus_Kamerasicht_Real)
	- Zuordnung:
		Minimierungsproblem fuer jede Boundingbox: min i |(y, z)_theoretisch_Foto_i - (y, z)_Mittelpunkt_Boundingbox| 
		(y, z)_theoretisch_Foto_i = Berechnete Fotoposition von Objekt i zu diesem Zeitpunkt. Manche der n Objekte haben keinen Wert, da sie zu dem Zeitpunkt ausserhalb des Detektionsbereiches sind.
	- Erste Ausreisserbehandlung: Wenn Minimalwert sehr gross ist wird die Bounding Box keinem Verkehrsobjekt zugeordnet.
Zwischenergebnis: Fuer jedes Detektionsobjekt zu jedem Zeitpunkt wo eine sinnvolle Bounding Box erstellt wurde die Hoehe und Breite in Pixeln
4. Mit c_Hoehe, c_Breite, x_aus_Kamerasicht_Real und Hoehe_Foto bzw. Breite_Foto: Hoehe_Real und Breite_Real schaetzen
	Hoehe_Real = Hoehe_Foto * c_height * x_aus_Kamerasicht_Real
	Breite_Real = Breite_Foto * c_width * x_aus_Kamerasicht_Real	
Vorlaeufiges Ergebnis: Fuer jedes Detektionsobjekt zu jedem Zeitpunkt wo eine Bounding Box erstellt wurde geschaetzte Hoehe_Real und Breite_Real in Metern
5. Ausreisserbehandlung
	- Fuer jedes Detektionsobjekt und fuer Hoehe und Breite individuell.
	- Falls eine Hoehe bzw. Breite um 3 Standardabweichungen von Mittelwert der Gruppe entfernt ist, wird der entsprechende Wert geloescht.
Endergebnis: Arithmetisches Mittel ueber alle Hoehen und Breiten (exklusive Ausreisser) pro Detektionsobjekt
(
6. Testen: Falls Ground Truth Breiten und Hoehen bekannt: Mittlere absolute Abweichungen bestimmen:
mean(abs(Breite_berechnet(i) - Breite_ground_truth(i))) 
mean(abs(Hoehe_berechnet(i) - Hoehe_ground_truth(i)))
)


==========


Training

1. Ground Truth Hoehe_Real und Breite_Real vorhanden, x_aus_Kamerasicht_Real-Hoehe- bzw. x_aus_Kamerasicht_Real-Breite-Paare vorhanden
2. Daraus Trainingsdatensatz bauen
3. Per Kleinste Quadrate c-Hoehe bzw. c_Breite schaetzen
	Breite_Real = Breite_Foto * x_aus_Kamerasicht_Real * c_width
	Hoehe_Real = Hoehe_Foto * x_aus_Kamerasicht_Real * c_height
